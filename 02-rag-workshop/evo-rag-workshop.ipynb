{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f41a43",
   "metadata": {},
   "source": [
    "# RAG Workshop: From Basic to Advanced Retrieval-Augmented Generation\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this workshop, you will understand:\n",
    "\n",
    "1. **What is RAG?** - Retrieval-Augmented Generation fundamentals\n",
    "2. **Vector Stores** - How to store and search documents using embeddings\n",
    "3. **Document Processing** - Loading, splitting, and preparing documents\n",
    "4. **Query Enhancement** - Advanced techniques to improve retrieval\n",
    "5. **RAG Evolution** - From basic to advanced implementations\n",
    "\n",
    "## 🏰 Context: Curse of Strahd Campaign\n",
    "\n",
    "This workshop uses a **Dungeons & Dragons campaign** as our data source. We'll build a RAG system that can answer questions about campaign events, characters, and story arcs. This makes the learning more engaging than typical boring corporate documents!\n",
    "\n",
    "## 📚 What You'll Build\n",
    "\n",
    "- **Basic RAG**: Simple question → find documents → generate answer\n",
    "- **Enhanced RAG**: Query rewriting for better retrieval\n",
    "- **Advanced RAG**: Query decomposition with multiple retrievals\n",
    "\n",
    "Let's start our journey into the world of RAG! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6fc75",
   "metadata": {},
   "source": [
    "## 🔧 Step 1: Environment Setup\n",
    "\n",
    "Before we dive into RAG, let's set up our environment. We'll:\n",
    "\n",
    "1. **Install Dependencies**: All required packages for our RAG system\n",
    "2. **Import Core Libraries**: LangChain for RAG orchestration\n",
    "\n",
    "**Why LangChain?** It's a popular framework that makes building RAG systems much easier by providing pre-built components for document loading, text splitting, embeddings, and chains."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T18:11:45.431902Z",
     "start_time": "2025-07-22T18:10:35.875660Z"
    }
   },
   "source": "! pip install -r ./requirements.txt",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core==0.3.69 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 1)) (0.3.69)\n",
      "Requirement already satisfied: langchain-openai==0.3.28 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 2)) (0.3.28)\n",
      "Requirement already satisfied: langchain-community==0.3.27 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 3)) (0.3.27)\n",
      "Requirement already satisfied: langchain-text-splitters==0.3.8 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 4)) (0.3.8)\n",
      "Requirement already satisfied: langchainhub==0.1.21 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 5)) (0.1.21)\n",
      "Requirement already satisfied: unstructured==0.18.9 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 6)) (0.18.9)\n",
      "Requirement already satisfied: markdown==3.8.2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 7)) (3.8.2)\n",
      "Requirement already satisfied: elasticsearch==8.18.1 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 8)) (8.18.1)\n",
      "Requirement already satisfied: langchain-elasticsearch==0.3.2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from -r ./requirements.txt (line 9)) (0.3.2)\n",
      "Collecting streamlit==1.39.0 (from -r ./requirements.txt (line 10))\n",
      "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (1.97.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (2.32.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (3.12.14)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (2.3.1)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langchainhub==0.1.21->-r ./requirements.txt (line 5)) (2.32.4.20250611)\n",
      "Requirement already satisfied: chardet in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (5.2.0)\n",
      "Requirement already satisfied: filetype in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (6.0.0)\n",
      "Requirement already satisfied: nltk in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (4.13.4)\n",
      "Requirement already satisfied: emoji in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (2.14.1)\n",
      "Requirement already satisfied: python-iso639 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (3.13.0)\n",
      "Requirement already satisfied: backoff in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: unstructured-client in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (0.39.1)\n",
      "Requirement already satisfied: wrapt in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.17.2)\n",
      "Requirement already satisfied: tqdm in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (7.0.0)\n",
      "Requirement already satisfied: python-oxmsg in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (0.0.2)\n",
      "Requirement already satisfied: html5lib in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (8.17.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (2.9.0.post0)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from streamlit==1.39.0->-r ./requirements.txt (line 10)) (8.2.1)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<11,>=7.1.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pillow-10.4.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from streamlit==1.39.0->-r ./requirements.txt (line 10)) (6.5.1)\n",
      "Collecting watchdog<6,>=2.1.5 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading watchdog-5.0.3-py3-none-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (1.20.1)\n",
      "Requirement already satisfied: jinja2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (4.25.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading narwhals-1.48.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from click<9,>=7.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (2.5.0)\n",
      "Requirement already satisfied: certifi in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (2025.7.14)\n",
      "Requirement already satisfied: simsimd>=3 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch==0.3.2->-r ./requirements.txt (line 9)) (6.5.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (0.16.0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from pydantic>=2.7.4->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from pydantic>=2.7.4->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from pydantic>=2.7.4->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (3.4.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (0.26.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langsmith>=0.3.45->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langsmith>=0.3.45->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from langsmith>=0.3.45->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (0.23.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from python-dateutil->elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from beautifulsoup4->unstructured==0.18.9->-r ./requirements.txt (line 6)) (2.7)\n",
      "Requirement already satisfied: webencodings in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from html5lib->unstructured==0.18.9->-r ./requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: joblib in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from nltk->unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: olefile in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from python-oxmsg->unstructured==0.18.9->-r ./requirements.txt (line 6)) (0.47)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (45.0.5)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (5.8.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\projects\\evo-rag\\evo-rag-workshop\\lib\\site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (2.22)\n",
      "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.7 MB 857.0 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.3/8.7 MB 1.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.6/8.7 MB 1.2 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.8/8.7 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.4/8.7 MB 1.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.9/8.7 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 3.4/8.7 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.9/8.7 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 4.5/8.7 MB 1.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.0/8.7 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.8/8.7 MB 1.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.3/8.7 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.1/8.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.7 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 2.2 MB/s eta 0:00:00\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pandas-2.3.1-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.1/11.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading pillow-10.4.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-5.0.3-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading narwhals-1.48.0-py3-none-any.whl (376 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/26.1 MB 5.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.4/26.1 MB 5.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.4/26.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.7/26.1 MB 5.6 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.8/26.1 MB 5.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.6/26.1 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.6/26.1 MB 5.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 9.2/26.1 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.5/26.1 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.8/26.1 MB 5.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.1/26.1 MB 5.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 14.2/26.1 MB 5.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.5/26.1 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.8/26.1 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.4/26.1 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.7/26.1 MB 5.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.2/26.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.1/26.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.6/26.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 5.9 MB/s eta 0:00:00\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, watchdog, tzdata, toml, smmap, pyarrow, protobuf, pillow, narwhals, mdurl, cachetools, blinker, pydeck, pandas, markdown-it-py, gitdb, rich, gitpython, altair, streamlit\n",
      "\n",
      "   ----------------------------------------  0/20 [pytz]\n",
      "   ----------------------------------------  0/20 [pytz]\n",
      "   -- -------------------------------------  1/20 [watchdog]\n",
      "   -- -------------------------------------  1/20 [watchdog]\n",
      "   -- -------------------------------------  1/20 [watchdog]\n",
      "   ---- -----------------------------------  2/20 [tzdata]\n",
      "   ---- -----------------------------------  2/20 [tzdata]\n",
      "   ---- -----------------------------------  2/20 [tzdata]\n",
      "   ------ ---------------------------------  3/20 [toml]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ------------ ---------------------------  6/20 [protobuf]\n",
      "   ------------ ---------------------------  6/20 [protobuf]\n",
      "   ------------ ---------------------------  6/20 [protobuf]\n",
      "   ------------ ---------------------------  6/20 [protobuf]\n",
      "   ------------ ---------------------------  6/20 [protobuf]\n",
      "   ------------ ---------------------------  6/20 [protobuf]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   -------------- -------------------------  7/20 [pillow]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ---------------- -----------------------  8/20 [narwhals]\n",
      "   ------------------ ---------------------  9/20 [mdurl]\n",
      "   ---------------------- ----------------- 11/20 [blinker]\n",
      "   ------------------------ --------------- 12/20 [pydeck]\n",
      "   ------------------------ --------------- 12/20 [pydeck]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   -------------------------- ------------- 13/20 [pandas]\n",
      "   ---------------------------- ----------- 14/20 [markdown-it-py]\n",
      "   ---------------------------- ----------- 14/20 [markdown-it-py]\n",
      "   ---------------------------- ----------- 14/20 [markdown-it-py]\n",
      "   ---------------------------- ----------- 14/20 [markdown-it-py]\n",
      "   ---------------------------- ----------- 14/20 [markdown-it-py]\n",
      "   ------------------------------ --------- 15/20 [gitdb]\n",
      "   ------------------------------ --------- 15/20 [gitdb]\n",
      "   -------------------------------- ------- 16/20 [rich]\n",
      "   -------------------------------- ------- 16/20 [rich]\n",
      "   -------------------------------- ------- 16/20 [rich]\n",
      "   -------------------------------- ------- 16/20 [rich]\n",
      "   -------------------------------- ------- 16/20 [rich]\n",
      "   ---------------------------------- ----- 17/20 [gitpython]\n",
      "   ---------------------------------- ----- 17/20 [gitpython]\n",
      "   ---------------------------------- ----- 17/20 [gitpython]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   ---------------------------------------- 20/20 [streamlit]\n",
      "\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 cachetools-5.5.2 gitdb-4.0.12 gitpython-3.1.44 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.48.0 pandas-2.3.1 pillow-10.4.0 protobuf-5.29.5 pyarrow-21.0.0 pydeck-0.9.1 pytz-2025.2 rich-13.9.4 smmap-5.0.2 streamlit-1.39.0 toml-0.10.2 tzdata-2025.2 watchdog-5.0.3\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "788a1d23",
   "metadata": {},
   "source": [
    "## 🤖 Step 2: Setting Up the Language Model (LLM)\n",
    "\n",
    "Now we'll configure our **Azure OpenAI** model. This is the \"brain\" of our RAG system that will:\n",
    "\n",
    "- **Generate Answers**: Create human-like responses based on retrieved documents\n",
    "- **Process Queries**: Understand and work with user questions\n",
    "- **Follow Instructions**: Use our custom prompts to behave like a D&D assistant\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Temperature = 0.0**: Makes responses consistent and deterministic (less creative, more factual)\n",
    "- **GPT-4 Mini**: A cost-effective version of GPT-4 that's perfect for most RAG use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b753e",
   "metadata": {},
   "source": [
    "### 🧪 Testing the LLM (Without RAG)\n",
    "\n",
    "Let's first test our LLM **without** any retrieved documents. This will show you why we need RAG!\n",
    "\n",
    "**What to expect:** The model won't know about Milos and Ireena (characters from our D&D campaign) because they're not in its training data. This demonstrates the **knowledge cutoff problem** that RAG solves."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:03:34.599188Z",
     "start_time": "2025-07-22T10:03:30.004320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://evozon-bots-new.openai.azure.com/'\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = '1906f94ca9a24877ab2423c4cf4b746c'\n",
    "os.environ['OPENAI_API_VERSION'] = '2024-12-01-preview'\n",
    "# Create the LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment='gpt-4.1-mini',\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "messages = [(\"user\", \"What happened between Milos and Ireena?\")]\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ],
   "id": "2433f6a45582b79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Could you please provide more context about Milos and Ireena? Are they characters from a specific book, movie, game, or another story? That way, I can give you a more accurate answer.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 17, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_178c8d546f', 'id': 'chatcmpl-Bw48MUGg36lf1IRtCC7H9s1jo1pkP', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--e9978a3a-5742-4216-8274-87bb11ce6fc0-0' usage_metadata={'input_tokens': 17, 'output_tokens': 43, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c3b7115c",
   "metadata": {},
   "source": [
    "### 📋 Understanding LLM Responses\n",
    "\n",
    "This utility function helps us see **all the information** that comes back from the LLM, not just the text response. This is useful for debugging and understanding how the model works.\n",
    "\n",
    "**Response Components:**\n",
    "- **Content**: The actual text answer\n",
    "- **Additional kwargs**: Extra parameters or metadata\n",
    "- **Response metadata**: Information about the model, tokens used, etc."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:03:41.222701Z",
     "start_time": "2025-07-22T10:03:41.207753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pretty_print_response(response):\n",
    "    \"\"\"Prints the response in a readable format.\"\"\"\n",
    "    print(\"Response:\", response.content)\n",
    "    print(\"Additional args\", response.additional_kwargs)\n",
    "    print(\"Metadata:\", response.response_metadata)\n",
    "\n",
    "pretty_print_response(response)"
   ],
   "id": "d24770ecfb47836f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Could you please provide more context about Milos and Ireena? Are they characters from a specific book, movie, game, or another story? That way, I can give you a more accurate answer.\n",
      "Additional args {'refusal': None}\n",
      "Metadata: {'token_usage': {'completion_tokens': 43, 'prompt_tokens': 17, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_178c8d546f', 'id': 'chatcmpl-Bw48MUGg36lf1IRtCC7H9s1jo1pkP', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "b16f55f5",
   "metadata": {},
   "source": [
    "## 🔢 Step 3: Understanding Embeddings - The Magic Behind Vector Search\n",
    "\n",
    "**What are embeddings?** Think of them as \"DNA for text\" - they convert words and sentences into numbers (vectors) that capture their meaning.\n",
    "\n",
    "### 🧠 How Embeddings Work:\n",
    "1. **Text → Numbers**: \"The knight fought bravely\" becomes [0.2, -0.1, 0.8, 0.3, ...]\n",
    "2. **Similar Meaning → Similar Numbers**: Related concepts cluster together in vector space\n",
    "3. **Searchable**: We can find similar documents by comparing these numbers\n",
    "\n",
    "**Why Azure OpenAI Embeddings?** They're trained on massive datasets and understand context, synonyms, and relationships between concepts much better than simple keyword matching.\n",
    "\n",
    "### 💡 Real Example:\n",
    "- \"What happened to Ireena?\" \n",
    "- \"Tell me about Ireena's fate\"\n",
    "- \"Ireena's story\"\n",
    "\n",
    "All these have similar embeddings even though they use different words!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:03:54.333167Z",
     "start_time": "2025-07-22T10:03:53.842050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"embed-new\"\n",
    ")"
   ],
   "id": "3c8b2c7dec42a0f2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "b1ec8238",
   "metadata": {},
   "source": [
    "## 📚 Step 4: Loading Documents - Feeding Knowledge to Our RAG System\n",
    "\n",
    "Time to load our **knowledge base**! We're using Curse of Strahd campaign notes as our data source.\n",
    "\n",
    "### 🔍 What's Happening:\n",
    "1. **DirectoryLoader**: Scans the `docs/` folder for all Markdown files\n",
    "2. **UnstructuredMarkdownLoader**: Knows how to read Markdown files and preserve structure\n",
    "3. **Glob Pattern**: `**/*.md` means \"find all .md files in any subdirectory\"\n",
    "\n",
    "### 📖 Our Data Structure:\n",
    "```\n",
    "docs/\n",
    "└── Curse of Strahd.md  (Contains campaign notes, character interactions, plot events)\n",
    "└── History of Barovia.md  (Historical context, important locations)\n",
    "└── Lore of Barovia.md  (Myths, legends, and background information)\n",
    "└── Strahd von Zarovich.md  (Character profile, motivations, and backstory)\n",
    "\n",
    "```\n",
    "\n",
    "**Why Markdown?** It's human-readable, maintains structure (headers, lists), and is easy to process programmatically."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:04:06.248002Z",
     "start_time": "2025-07-22T10:03:58.330931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, UnstructuredMarkdownLoader\n",
    "\n",
    "loader = DirectoryLoader(\"docs/\", glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ],
   "id": "d4905d48516ef49c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "12e17e0d",
   "metadata": {},
   "source": [
    "## ✂️ Step 5: Text Splitting - Breaking Documents into Digestible Chunks\n",
    "\n",
    "**Why split documents?** Large documents are like trying to eat a whole pizza at once - it's overwhelming and ineffective!\n",
    "\n",
    "### 🍕 The Chunking Strategy:\n",
    "- **Chunk Size: 2000 characters** - Sweet spot for context without overwhelming the LLM\n",
    "- **Overlap: 100 characters** - Ensures we don't lose context at chunk boundaries\n",
    "- **Recursive Splitting** - Tries to split on natural boundaries (paragraphs, sentences, words)\n",
    "\n",
    "### 🧩 How RecursiveCharacterTextSplitter Works:\n",
    "1. Try to split on double newlines (paragraphs)\n",
    "2. If still too big, split on single newlines (sentences)\n",
    "3. If still too big, split on spaces (words)\n",
    "4. Last resort: split by characters\n",
    "\n",
    "### 💡 Why This Matters:\n",
    "- **Better Retrieval**: Smaller, focused chunks are easier to match with queries\n",
    "- **LLM Context Limits**: Most models have token limits\n",
    "- **Relevance**: You get the exact information you need, not the whole document"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:04:29.702950Z",
     "start_time": "2025-07-22T10:04:29.643269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ],
   "id": "93a72b1197341d86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "ee49385e",
   "metadata": {},
   "source": [
    "## 🗃️ Step 6: Vector Store - The Heart of Our RAG System\n",
    "\n",
    "**What's a Vector Store?** Think of it as a super-smart database that stores documents alongside their embeddings and can find similar content lightning-fast.\n",
    "\n",
    "### ⚡ Why Elasticsearch?\n",
    "- **Scalable**: Handles millions of documents effortlessly\n",
    "- **Fast**: Optimized for vector similarity search\n",
    "- **Hybrid Search**: Combines semantic (meaning) and keyword search\n",
    "- **Production Ready**: Used by major companies worldwide\n",
    "\n",
    "### 🔧 Configuration Breakdown:\n",
    "- **es_url**: Where our Elasticsearch instance is running (localhost)\n",
    "- **index_name**: Like a database table name for our documents\n",
    "- **embedding**: The embedding model we set up earlier\n",
    "- **es_user/es_password**: Authentication credentials\n",
    "- **verify_certs: False**: For development (disable SSL verification)\n",
    "\n",
    "### 🎯 What Happens Next:\n",
    "We'll store our document chunks WITH their embeddings, so when you ask \"What happened to Ireena?\", it can find all chunks that are semantically similar to your question!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:05:24.198309Z",
     "start_time": "2025-07-22T10:05:23.992664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "\n",
    "ELASTIC_SEARCH_INDEX = \"rag-workshop\"\n",
    "\n",
    "\n",
    "elastic_vector_search = ElasticsearchStore(\n",
    "    es_url=\"https://localhost:9200/\",\n",
    "    index_name=ELASTIC_SEARCH_INDEX,\n",
    "    embedding=embeddings,\n",
    "    es_user=\"elastic\",\n",
    "    es_password=\"xM-_eV5Zqk3yjNqO*ld6\",\n",
    "    es_params={\"verify_certs\": False}\n",
    ")"
   ],
   "id": "be3415990a4dc94c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "585a1a2d",
   "metadata": {},
   "source": [
    "### 📥 Indexing Documents - Building Our Knowledge Base\n",
    "\n",
    "This is where the magic happens! We're about to:\n",
    "\n",
    "1. **Generate Embeddings**: Convert each text chunk to vectors using Azure OpenAI\n",
    "2. **Store Everything**: Save both the original text AND embeddings in Elasticsearch\n",
    "3. **Build Search Index**: Create optimized structures for fast similarity search\n",
    "\n",
    "### ⏱️ What to Expect:\n",
    "- This might take a few minutes depending on document size\n",
    "- Each chunk gets processed through the embedding model\n",
    "- Progress might be shown as documents are indexed\n",
    "\n",
    "**Fun Fact**: After this step, you can search for \"vampire lord\" and it might find chunks mentioning \"Strahd\" even if they don't contain the exact words!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T17:04:57.087539Z",
     "start_time": "2025-07-21T17:04:36.028736Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['07354455-d202-4d30-a6f8-51cbddb8f2ac',\n",
       " '775f3c52-1a88-47a8-9768-bb1d99c7c01f',\n",
       " 'b1e50a09-6a9e-463b-bd70-eb97e99eecc9',\n",
       " '1022e611-22de-492d-8a20-b6fdf7cd3b04',\n",
       " '2219686c-2fb9-49be-918e-8675b1de4620',\n",
       " 'b9fc9741-04d9-4336-8854-b215afab6963',\n",
       " 'ce6fd665-92c6-4876-a2ac-06797ab9aaf2',\n",
       " '995d1299-ad96-4863-a63d-0cd12e94ee57',\n",
       " 'f1b6130d-4706-42ba-a298-0e1478b1150c',\n",
       " '9e2cdc55-e4a9-4200-bfc1-94d28f7c9047',\n",
       " '01ad3762-f910-4f6e-9e63-a61cb8aefe43',\n",
       " 'b641bd8d-24b0-4e02-bd59-00719a8cd864',\n",
       " 'dcd0fef8-8637-431f-a1e9-95c59b925eb2',\n",
       " '3c7dab2d-5fbf-4d55-9d19-7325e3ee07b2',\n",
       " '2a49ec5c-cb09-4348-9585-b1a4e890cfe2',\n",
       " '73b4b628-2884-404d-b5fc-4b087ce0fbc9',\n",
       " 'a27ccaac-f02a-402c-8ee8-ed378f33dd91',\n",
       " '58efd914-997f-49a9-83f3-5b418344cbb4',\n",
       " 'f3232bc2-41fb-431d-94e1-1ee092378212',\n",
       " '62286482-d4ad-486d-b900-a25b713c0222',\n",
       " '88eda36e-6d00-4939-921c-ce4ab1a7df4d',\n",
       " '7f1b1e3e-4676-44f6-bec5-fd1499a996bd',\n",
       " '9d636373-d04b-4b90-a743-a7044881a96b',\n",
       " '6788b9e3-7c5b-40bb-a04f-3b0b0587cb37',\n",
       " '157c20dd-c8ae-44bb-aca3-777a10828680',\n",
       " '32a74e2f-76fa-4ac0-817a-bae91272e63d',\n",
       " '69ee1a44-9209-4210-882d-98c64dc25d8c',\n",
       " '62361702-ec6b-4eda-9c1e-fcf9c79ab6cb',\n",
       " '7db0ffc3-b143-43c5-9fda-a9123b20db9a',\n",
       " '3b9f77e1-282a-4128-85fc-201da599c2a7',\n",
       " '9fa85df1-e882-44c7-81df-feb091883661',\n",
       " 'aea6752b-2b0d-4d57-85e3-5a980a63266b',\n",
       " '12d35b71-cf90-4508-b239-146a73d0fe76',\n",
       " 'd32b3b1d-2533-4cea-ad51-9b1746753100',\n",
       " '9fdafcd3-a581-4668-b281-242bbbcb63b4',\n",
       " '9f082b1c-c8ee-49e2-bb3f-dd1f7b7b12be',\n",
       " '59b71cc9-1ea7-4c82-ae12-81a8732a393d',\n",
       " '4b4906e4-cc49-4a30-9c57-1691dc223f3e',\n",
       " '72456eef-31db-4d11-9d44-fb82b8531a12',\n",
       " '3364d003-d1db-449d-9a3c-602754d2df31',\n",
       " '19032bba-be8a-46fd-9a4f-a423c0cba4c0',\n",
       " '2012858c-c322-4d78-aa64-c843fb3413d2',\n",
       " 'ea5f4cc1-b37a-430c-acf5-55c28f58c02f',\n",
       " 'd7f58fdb-97c6-451c-ab6c-94ded2806a44',\n",
       " '9f2ef02b-a428-4d66-8e40-fc2276b78486',\n",
       " 'a7962aa2-68ce-4a89-82b4-e7ff6c9a0862',\n",
       " '460b1344-ebf1-4a6b-a950-1894c847c6f9',\n",
       " '53b623a8-ab38-4e06-9a30-2893bae12f43',\n",
       " '42c4fe45-ec51-438c-9ea1-596843b3cb1a',\n",
       " 'e74dff5c-0401-41ae-bda7-fcbdd5e29d94',\n",
       " '17f6fb2f-744d-43b3-a449-88833c30b09b',\n",
       " '3be95d6e-948b-41ae-8151-2f728b14ff7a',\n",
       " '9c870333-a780-4767-b10f-3d1b8cc1c490',\n",
       " '2d21f06b-98c3-46db-85f7-f85c6b328ae7',\n",
       " '91e99ed2-70f8-405e-9a79-60188d94b571',\n",
       " '798d474b-5f0f-43b4-ac0e-c56777dbcf36',\n",
       " '3464892c-592d-4ef9-910f-bb9a9cb0e56f',\n",
       " 'b2d95cb4-c26d-49e7-939b-0fa95d053023',\n",
       " 'd5aa7527-3b9d-4efe-9059-4f5e86e46bbc',\n",
       " '7e68d0fa-79a7-4762-9448-c846457923b6',\n",
       " 'e7e0e29f-491e-4f6e-8d9c-79089ace67bb',\n",
       " 'ddc775d1-04f9-447e-8c6c-6b165f1de9e4',\n",
       " 'feae5b1a-1182-430b-9ba3-adbdec0feec0',\n",
       " '6ab6c9e1-c878-451d-a8f7-f1a4cb2a7900',\n",
       " 'ae4ca46a-7137-4cbe-90da-1027a15427da',\n",
       " 'eee1e554-9d71-43af-8011-b129ae2aa7d3',\n",
       " 'b3ea3fa4-33ba-4990-8c93-dc930b75ef46',\n",
       " '2dca4b69-759b-4ef5-9c98-fa44473c8f08',\n",
       " 'ff061a18-6cdd-4b5f-a332-b0d194b04ca4',\n",
       " 'f034eaad-52cd-4f9e-9749-69689a583feb',\n",
       " '18cdf202-e41d-4e58-9ef9-0024ffab24e3',\n",
       " '2289840b-d98d-4807-8405-871c9fc10623',\n",
       " 'c3efa749-7a8e-46c7-90a0-649f1cfce57b',\n",
       " 'a1260b15-501d-48ff-bc52-0a48fe8fdd3b',\n",
       " '839e477e-a657-401b-9cfe-5f7ddfbd5969',\n",
       " '192cb8dc-c220-4240-9975-06ab478ca791',\n",
       " '6e120da2-59b1-46c4-9ce0-20772ab7a3a2',\n",
       " 'd43eec1b-f53c-4295-91c4-07725dcb166c',\n",
       " '70cc4555-648f-4032-bc13-a72411185344',\n",
       " '3beed962-d816-4c36-9dd7-90e3f40efc37',\n",
       " 'cb4f05a0-43de-48f2-8a90-7622b2ee3138',\n",
       " '484cde4b-ad87-49ec-87ca-cbe3ff1b0df3',\n",
       " '65b424b8-fa68-49c3-b7bb-01583f6b07c6',\n",
       " 'e2b5b8fd-a153-40f3-b985-188d0284ca84',\n",
       " '44f2c390-9f30-4f7b-bd59-5b013397b6dc',\n",
       " '1a7b342b-895c-44b4-b9e9-ad0d8e8cc724',\n",
       " 'f5b19f62-0dc1-49c3-b7fb-1ca03905dc05',\n",
       " '9cf84d40-4858-45a8-b139-31ed7146539d',\n",
       " '7ffa9ca4-9e44-47c4-bf24-5460fdf5c20b',\n",
       " 'd0521d51-0677-418c-be0e-d33270211689',\n",
       " '2ee99ac0-d06e-4420-abf9-7608ab8bf449',\n",
       " '2040cde5-740d-47ec-ad4a-ded4bf80d807',\n",
       " 'de8980df-1ac6-474c-b48f-5e7e6e013805',\n",
       " 'b6e4691b-c7df-4408-878a-2b7ff134c56c',\n",
       " '5028922f-7fe1-4805-8d65-921abe898262',\n",
       " 'dacd1faa-aada-4b7e-bacf-58041783b5fc',\n",
       " '15d13876-2ff1-4298-8a85-e7d3bd540838',\n",
       " 'c7541fde-fdb2-40c5-ab86-84da191f57eb',\n",
       " '4ff5f5be-f804-4819-84eb-455832ac3369',\n",
       " '79003a06-a9c5-4559-b75c-7cf59076a0e1',\n",
       " 'ee03b00f-d441-4679-aa45-1f375196fa2a',\n",
       " '2977f96c-9525-4e69-95fe-08c687db326e',\n",
       " 'f823f07c-bca9-4602-bda3-f0476bb914b1',\n",
       " 'c40bbba8-b5eb-4339-a17f-aa80403c4b98',\n",
       " '9d76c618-b2d1-46c3-9179-c5e96532cc9f',\n",
       " 'c1c22957-3b0a-4ede-a9ba-683c41c0f4f5',\n",
       " '07bea8d9-b631-4a10-8191-d22cb4c2b2db',\n",
       " 'a50892fc-bc81-4a12-8bce-11c772568965',\n",
       " '36f485ff-322c-4e9b-9af2-4d768adfd4db',\n",
       " '3d683566-6da0-49f8-b295-38aadb7b87fb',\n",
       " '96ebdc6f-2196-481e-bf2c-da137d48b221',\n",
       " 'b874933b-e05d-4f77-9f4a-80fdbbfea917',\n",
       " '9a03713a-c0a3-43fd-98bb-e1ae4b3a4053',\n",
       " '505f98ad-2c4b-4eef-8935-cb5a7e3db5c2',\n",
       " 'a7e67a4a-e442-43ae-844b-8e29a547130d',\n",
       " '6f27cce8-64cd-499d-9b3a-6165f4536df3',\n",
       " 'c45bcc30-d0b4-4d8c-847a-49a805ac3dfa',\n",
       " '6ce8eed1-4d3a-4061-990e-258814bde129',\n",
       " '8e164c56-aaed-41ed-9a56-e5a8756e97d5',\n",
       " '88273f56-833e-430a-84e4-f250c7c8d3f4',\n",
       " 'c991deca-352b-4730-8d67-e5a533236c2e',\n",
       " '10e92cb7-549a-4393-b386-bebdb30faa8b',\n",
       " '2a0eab2b-4a3d-4452-89d4-e186661d5963',\n",
       " '6e22c684-66c3-4ea2-af9a-87770c81f44c',\n",
       " '25c3e745-99e0-416f-9622-00f50d6157f5',\n",
       " 'a1368538-2b3f-4af4-ba36-d5422c255d83',\n",
       " 'ee575e7e-a30d-4821-b1f7-a222a78a3548',\n",
       " '38f8e9f5-646e-49ed-b77e-e668f5e1a1d5',\n",
       " '280ca90a-83bc-4b91-93cf-eda62df64ac4',\n",
       " 'c8837323-d9b1-409b-97d7-f5e8bf49e1de',\n",
       " '50bbc4f9-9728-4267-af52-037c0adf069b',\n",
       " '0a60ebfe-2460-41fb-8741-08669854e66a',\n",
       " 'bee80a46-2876-4443-9afb-97dcc0c5bae5',\n",
       " 'ca8b5fea-46c8-4929-90db-a38925a9fe4d',\n",
       " '68574f8c-24d1-4081-bc2c-43cec2dcc86c',\n",
       " '670a99fc-004d-4626-a3ea-b94cf52077e7',\n",
       " '79f43b4a-225d-47fe-a07f-152e3d5d0ed0',\n",
       " '42400173-906a-413d-a1ba-0098ba992263',\n",
       " '9031e9d9-5b6c-4272-bb96-8bc22b35790d',\n",
       " '35e84339-111e-447e-8977-44bd33a0ad73',\n",
       " '70e1efa6-9573-49f6-8a34-9c312f90aacf',\n",
       " '5fdba284-83cb-433d-926f-a0cb0e8592e7',\n",
       " '4168855e-c8e8-470e-a891-bd658a361bce',\n",
       " 'dc58567f-6047-4062-9b22-77cb4cb0680b',\n",
       " '2cfba39f-289d-4391-b0a7-00157043c601',\n",
       " 'f9ba1f09-6abc-4299-9648-9ebf5a8b109b',\n",
       " 'b0a1efee-f26e-4d2d-be75-3a112b69d967',\n",
       " '6d49c5c8-7a42-4cfa-a463-b66b86c54a34',\n",
       " '3a24a1d5-1620-4fa6-b949-2825b9b0b9f2',\n",
       " '8ab578e7-8eeb-4325-8868-fe1d052e4050',\n",
       " '4442450c-4596-4629-bff6-0cbdf450604a',\n",
       " 'a4af25a0-ad75-413b-9aba-ede802311eeb',\n",
       " '1cf94502-c008-4996-a2d1-275594ed64ee',\n",
       " '6a16aa31-5723-4436-bebe-e125bb5ce166',\n",
       " '77c36700-052a-42e4-9e3d-ae594e902ed3',\n",
       " '978011f3-6dc9-4889-9c4f-e8da5d9c70f1',\n",
       " 'e51f11db-2638-44ed-8a30-d9d6974402d1',\n",
       " '4983c84a-49cf-4e4c-a690-4bc997f9a7a4',\n",
       " '95c6f720-07de-45c1-8c5a-e00f33a175e7',\n",
       " '51c58e0b-9ea8-4df5-beab-d8e16e9bb313',\n",
       " '833e304d-ba4a-468f-b482-f19fbe3df1e2',\n",
       " '71652ed8-a0eb-45c5-a924-d9194f456d3f',\n",
       " '9a3689e8-ff09-4433-b077-0b0c217639a8',\n",
       " 'ecad4758-8113-4e58-96bb-0c96b7320c11',\n",
       " 'e2dfc16a-8b21-4770-98aa-de0e60529d60',\n",
       " '869ae6cc-31d2-4326-b8b3-3d5ea44e97c1',\n",
       " 'd6431379-7cfc-4147-891f-20badc486adc',\n",
       " '9fc4b788-e2e1-4a39-acb8-1d863ec68601',\n",
       " 'd551772b-e7be-4553-8303-f51a650a69c4',\n",
       " '7ad06379-7b77-4eea-9461-6f2c532639f1',\n",
       " '99630123-afcb-4130-88e0-507e18b54845',\n",
       " '3340e8ef-c829-4291-9a88-4c38fca63e35',\n",
       " '86cdcbe5-29c4-4861-bd9a-af001d35fb9d',\n",
       " '432e2b32-5e68-4484-9fff-378c71d95a36',\n",
       " 'f4ca4162-ce79-41b1-8558-64984162a743',\n",
       " 'c71d3033-317d-40e2-9be1-8de82638b999',\n",
       " '0e565edb-3182-4609-804a-3266ccbfbadd',\n",
       " 'c6cd2454-e150-4993-aaeb-350fd8edf358',\n",
       " '4c064432-def6-499c-bf6c-eaae66bff8a1',\n",
       " '27219c32-0206-47ce-aa9d-98a9dad5b801',\n",
       " '5709ed24-a4f5-41a4-8b86-82c1cadc7155',\n",
       " '7628e657-1aa3-4953-86f6-eab950c9ba09',\n",
       " '204e8ddf-378b-45f3-92d3-412d4ce05ca0',\n",
       " 'e43a415f-8411-49ca-8578-e3fa42bb5ea1',\n",
       " 'a55e28b2-62f0-4b79-b561-f18827814bbb',\n",
       " 'ae1811e9-01c8-4e02-b8e9-c2c13df73a9a',\n",
       " 'e184e537-068e-4b98-8130-e72c72d63167',\n",
       " 'e4868b94-350c-4857-b8e0-a690d9f26277',\n",
       " '3e3538a9-94e6-4f05-91c5-535ec8e14065',\n",
       " '0a4b8afb-015a-431c-b402-8a208cecf80b',\n",
       " '1504aff3-9f39-423f-9127-a3b3648e7a6c',\n",
       " 'e811a8f6-3a0f-4003-9799-3cb8144f2e34',\n",
       " 'c8392681-305c-49ad-b641-c5d7856fc510',\n",
       " 'b353a155-b7ef-4587-8cb4-3c17c2ba4c1a',\n",
       " 'e3ee887d-595f-4521-9717-1925bb7e8dc0',\n",
       " 'c5bd3ca5-2877-45a1-97a1-fa388928849b',\n",
       " '4b08608f-b93f-4fc3-ab39-27ea0389fbb6',\n",
       " '27997839-aadb-4656-880c-947b19f6f85e',\n",
       " '162503ac-0eac-4903-86f1-3b003a1d1f02',\n",
       " '64d7aac2-e034-407a-a274-514dff5f2635',\n",
       " 'ee0a8e62-76d5-4f14-a102-9ad69b8f045d',\n",
       " 'e151da34-c02a-4e6c-9019-88393dd88ecd',\n",
       " '1b467be0-76ec-42dd-b3b3-46b4a6f4966a',\n",
       " '01495ccd-774a-4976-a056-67a910d9c838',\n",
       " 'e574e901-b74c-45f3-ab8b-b9b5f8fe47f0',\n",
       " '86c640e4-7e7b-4a0e-9467-0e6c058dad2c',\n",
       " '212c64af-e970-496b-98e5-f3d7cdd539b7',\n",
       " 'b3ad9420-ab2b-4497-a83d-ab6180683a37',\n",
       " 'd58ccded-2974-437e-a287-639cbb3a6b1b',\n",
       " '88f0b48c-76db-4a57-9312-e1e67f0921e6',\n",
       " 'ae508853-eb34-4a15-92a4-e04ed81af31f',\n",
       " '0b6e7d22-7b18-43f6-bff2-84d48f3154f7',\n",
       " 'b5453ae3-f9d2-43a7-8f83-4a43209d67ef',\n",
       " '81a6718f-c369-4a13-b39e-addb09c83043',\n",
       " '75814f2e-e6b9-43b6-ade1-edb4b4b1b914',\n",
       " '003c8e02-31c1-4781-a348-6482c7fa45a9',\n",
       " 'b8aa3010-27fb-497e-87d8-2f14bcac572e',\n",
       " 'e52bad6d-c90f-4f28-81f2-50dc3754267e',\n",
       " '8a287cfc-b712-4290-b834-642ddf9ef610',\n",
       " '5521714a-d9fd-4648-988d-75b3be858604',\n",
       " '30027f3d-7e9d-42af-a1dc-a3835e062223',\n",
       " 'f2bcc6ca-aebd-4c27-b230-19be78faf98d',\n",
       " 'decb4f55-be53-4a17-861f-d7a497638dbc',\n",
       " '717e6e4a-c950-4cfa-89d0-9bab95acd181',\n",
       " '346401a6-c721-4d98-9594-4698c364b554',\n",
       " 'd9505a81-9786-40c7-a481-93a86c6ebeb6',\n",
       " 'c66b0a28-9f2b-47ce-8788-832697b4d3a8',\n",
       " '2e974529-370c-45f2-9da2-1c10ad728920',\n",
       " '823f6c61-a3a2-485c-a60f-79f9c9d258ff',\n",
       " 'a6d74466-a6db-4d07-ac47-2dfacb39cb91',\n",
       " '6d65a40f-bf8a-4200-8be8-80fa809fb52e',\n",
       " 'b50acdea-ebf7-46e5-8c4e-b97e9ff92caa',\n",
       " 'b4ef18b3-29d5-4c5d-9c5a-c499338ea767',\n",
       " 'c89b15a6-7772-482f-80db-c4592be64fd3',\n",
       " 'f416d061-10eb-41fb-9d49-9c546347efd8',\n",
       " 'b0a47658-8ceb-4ac9-a997-a6849e0800f2',\n",
       " '374716f5-c0b3-4062-a498-c9f39b632962',\n",
       " '1c6e369b-d043-4da7-9449-bb93613a4a86',\n",
       " '4d2aa5d6-f6e1-4228-b775-37a0b2567d46',\n",
       " '11c65d58-9f31-479e-bac5-0fd8030b40e9',\n",
       " 'fbe69642-1777-4600-a7f6-750bb34909d8',\n",
       " '719d027d-dc6b-4582-8064-02e2dad1b433',\n",
       " '488d1818-b154-4c9d-9e52-a2c064886620',\n",
       " '046ccecb-f62f-495c-bfd1-7b3edbed9053',\n",
       " '64bf7efa-fdd8-48aa-a59b-5b8d9ccc0af9',\n",
       " '910044dd-5c91-4aa3-b999-5ac053aa20f8',\n",
       " '6700d38a-e138-4800-b3ae-53f5113b27da',\n",
       " '2a716a6c-dfc8-4ad2-bc11-c55d09988973',\n",
       " 'cea74b20-7a98-4a55-b48e-3d7855953495',\n",
       " 'd202034f-808f-4b6a-b25e-f8538507929f',\n",
       " 'c9355416-737c-4915-9b03-f34a6d738245',\n",
       " 'f1002502-2f89-4ac6-8323-a5c259ecb48c',\n",
       " 'b2054992-428c-4901-b91c-5aa0f2f3a6d5',\n",
       " '74204b93-fa36-4406-9c87-cabf86711a83',\n",
       " '8cafdefc-03a5-412c-8b83-49b3b6246d88',\n",
       " 'fa4d58e6-4d2b-4e57-b28c-15b3771cc92a',\n",
       " '09612d88-e361-4069-b825-69a6fbc1e893',\n",
       " 'a801de9a-2cab-4181-bbdc-88efbeefbb54',\n",
       " '4838fc18-16c0-4592-9bc6-e73552204bfb',\n",
       " 'f80d3a3f-21e8-45f7-a7a3-757118b1e70b',\n",
       " 'd89b9119-20fd-49bc-9ab7-5ff735caa554',\n",
       " '88d6aa30-f334-4bc9-b861-f6d9389a09c6',\n",
       " '0c46e22e-dd69-41c4-b5b3-7277c4cf1d57',\n",
       " '7347ccc2-0efa-4e24-8d29-b786d33db123',\n",
       " 'c8bd64e9-25f8-48ed-8e1b-479c983aedaf',\n",
       " 'f8213c5e-1243-4cdc-9bb0-b142ac49bf2a',\n",
       " '5844582e-0251-45af-8442-45792463e487',\n",
       " 'e91bc5b5-d4a6-4bc4-a8bc-5d56b0cd89df',\n",
       " '933819e8-74a2-40cb-b53d-b04a6bea40a9',\n",
       " 'f79f96a8-4892-4d2a-8bb8-18497d37f4a2',\n",
       " 'dd38994b-eb30-49cd-94cf-4b3c8c2ac0c3',\n",
       " 'ad201844-cc8d-4d0f-9349-f633507cdf9b',\n",
       " '78716910-0f1e-4bde-aa71-5def478646a1',\n",
       " 'e257fc96-d1fd-4d59-a793-38edac81f0d8',\n",
       " '63f6218c-7c02-4c54-aed5-d8b52f27ada0',\n",
       " '4eb5db51-d2eb-40ef-954b-c5887f6e90ab',\n",
       " '5ba12ccf-26b9-48e2-a701-d26586cac2ad',\n",
       " 'b070ff22-d7ab-408b-8d4b-d0a5bf0a49dc',\n",
       " '1eadee54-02e7-410a-882f-a5b3b86738f6',\n",
       " '4c2fb848-4dbe-4a8b-966e-e0d8c9ec3e70',\n",
       " 'd416e0a8-6111-4493-9b54-dc93809ab3e0',\n",
       " '934b64c3-e97a-4011-b001-8d94f4cd65b5',\n",
       " 'a33da4dd-aa00-4bd8-911a-2c07db437f45',\n",
       " '7287de9d-6d4a-410b-8f5e-35e79f4dd15f',\n",
       " 'e08559d1-cc5d-4ad0-99bc-2e73e659b9a1',\n",
       " '67733da3-9e5a-48b6-9a69-8a76413bad65',\n",
       " '4e3412b5-6298-4e0f-9c0e-21bdeab62938',\n",
       " 'd8902ce3-e809-4627-9c67-b85a54590c7a',\n",
       " '2a2c5b49-0048-4188-8db5-11594be1ed99',\n",
       " '20ded5ed-697b-4d41-b46d-5ae37f676f56',\n",
       " '43a892a1-4dc5-4d4e-95df-43e4ba0127a6',\n",
       " '2061a8fd-6bd1-4603-96b5-347d2597367a',\n",
       " '668fcfc6-39a8-4fbb-bebf-914829331574',\n",
       " 'cfb846fa-e9ed-4db5-9f2b-034f0ff8a6f2',\n",
       " 'c582783b-a189-4bb2-bd54-11136681c52e',\n",
       " '6749538d-b2ef-428b-b48f-b656cb71f9e5',\n",
       " '5552e2a0-d35a-4687-8729-9d561d680183',\n",
       " '443c035f-f3f0-4fb3-85df-1ea5374250a0',\n",
       " '1190e107-7384-4807-b82e-b36b32f55ca4',\n",
       " '0529deb0-d9d4-4ffd-9786-832c1aeb1aeb',\n",
       " '233d4430-1156-4a4d-9fcf-b26da32949d3',\n",
       " 'a52dca62-e877-4d54-b775-ca26a02c1a7f',\n",
       " 'deda29c6-cecd-42e9-a7d5-f89efdba4ee7',\n",
       " 'f0bf9edc-d048-476f-a962-d9fec20de830',\n",
       " 'c964707f-954c-40c2-8662-004d3a3f7d5f',\n",
       " '5b22d8a1-4106-4495-9ddc-f1889cb8e3cc',\n",
       " '1db2bf5c-ef18-40e8-92da-dfe3fdbc739c',\n",
       " '9d05c233-ec4c-483c-bdea-9a6f3f69ac31',\n",
       " '88a75627-a718-4977-997f-8429a2fec439',\n",
       " '606aa4dc-3adb-4f56-bae9-dc8eb144cd94',\n",
       " 'ce4e0b00-846b-4329-b8fc-af1ef979636d',\n",
       " 'bba646a8-3b4d-4e07-a1e5-83bfc996238d',\n",
       " '9e097e90-a7ea-4317-97a3-d5e3ae1ea5b2',\n",
       " '12c821f8-8618-41b5-87b8-76b53e572c75',\n",
       " '0a54feac-0184-40a0-b6a9-67a05267d0f7',\n",
       " '0d6073c7-3fc8-4ead-8369-2dab6484cf4b',\n",
       " '262ca19f-1077-4088-81eb-b632ffa432af',\n",
       " '3c5b0cb1-868d-42e2-b875-33ca3381709c',\n",
       " '26bc1389-0130-478f-b103-190e9c37e2dc',\n",
       " '3fc1ac06-83fa-4e9a-a741-c97f2bd89cc0',\n",
       " 'bc8683eb-4852-417e-874c-b11c7a8d0c7b',\n",
       " '4e56124f-2b21-42f8-8a14-5f3517bdf17f',\n",
       " '1487be71-5fce-4508-b451-8b28fb88a4b8',\n",
       " '93178901-384f-4e23-87fd-b98e5c61dfb3',\n",
       " '333e1db2-51f2-4e02-ab2c-6f9baa1aeec0',\n",
       " '9c6966ec-27be-46dd-a887-94aeb4d57b00',\n",
       " 'e79e98c0-ef6c-4d2b-bf6d-2d332ca37b1d',\n",
       " '1aa5d388-a694-4c92-9ad0-5cb4dbb43cc4',\n",
       " '184f9d8a-3ffb-46d2-bba2-340015902bf4',\n",
       " '12ef6235-7f5f-4615-93a0-6afec26c16db',\n",
       " '3f734905-0061-4f37-b481-bacdb2fc533f',\n",
       " '1bdce9de-e797-4c1f-a21f-387587fadb3f',\n",
       " '1be79e67-6390-4394-bf79-563fcbfbca5d',\n",
       " '4d6e6b8b-fbf5-493c-ab8e-4e29d5abe467',\n",
       " '6c482615-6c9e-4c59-9c09-be18ba16d322',\n",
       " '0892c270-1079-452d-8aa7-7d0f36987d05',\n",
       " 'f851d29a-fb7a-4ed5-8702-13806cee96d4',\n",
       " 'e373f665-8cf4-466c-8ab5-e47cba5bba93',\n",
       " 'c5a5c4cb-ebbd-4f93-8208-9487e882b9df',\n",
       " '9c57d67c-0168-4c6f-8eed-f17bf26e93ad',\n",
       " '4af4b7a2-a180-47f3-b5aa-c85243b67de0',\n",
       " '3ac43617-abac-4265-87e3-22082fc16b77',\n",
       " '4bc5be27-7fa1-4ab2-bc2e-ddd491f58672',\n",
       " '3318b3b3-4e60-4589-aefc-a4ca73161382',\n",
       " 'c44b26fd-40b0-4b90-8e46-c508ff8171af',\n",
       " 'dabc1cf8-f591-4d71-9350-2c8bcd275909',\n",
       " '6791e973-9853-405d-b00d-68016bbfe929',\n",
       " 'fd0f9b56-15f7-4568-b222-1026e258e3d6',\n",
       " '27b8a69b-a169-46cb-b9d5-312a6d746e1b',\n",
       " '8f6ee8bd-bfb8-430f-934b-189d488935cf',\n",
       " 'd217b400-386d-496e-a8a5-272eeae15e4a',\n",
       " '5d5c5f1d-df2e-4f68-87c1-e7b60e763cfa',\n",
       " '1a55f55c-afaa-444f-be21-8d7c782f51b4',\n",
       " 'a59f453f-41c8-4269-bc33-bc6aa2aff306',\n",
       " '9b39f704-7e71-4a6e-931d-ddefe8a8dab4',\n",
       " 'f2dc2456-22ad-4802-b0c5-4faebef7ee3f',\n",
       " 'eac98185-1727-45b1-8338-7c404ecac81e',\n",
       " 'f306d647-f6a6-46cc-a17a-f9d9cff493c1',\n",
       " '561caaa6-7c19-464f-b9b3-70cf49adbe28',\n",
       " '2ddf02c4-5291-4980-a476-e4c9603a6069',\n",
       " 'bee9947c-4085-4a71-a9c6-eaafb13d47a7',\n",
       " 'ed840f27-7330-4224-aaea-9f34de3c7036',\n",
       " '4ab7a7c7-f84b-4162-8550-b40ec48fa670',\n",
       " '207bd472-1bf9-4abb-b9c0-fe4aeedbea26',\n",
       " 'f20809c8-8282-4c16-820f-c38a05e9a812',\n",
       " '0a39953b-6644-432b-b709-2cfaf2e66972',\n",
       " '190ce6e3-958f-4f0c-b3ed-d4d256117e28',\n",
       " '1eddc302-4545-4c19-95f1-feb8d8054beb',\n",
       " '35e8c616-7419-4ca2-8eee-fbdc1c61f4ff',\n",
       " 'e76db05f-5911-466b-9fbf-7f8a097f2ca7',\n",
       " 'd5466d34-0109-4e5b-ad59-910569b26279',\n",
       " 'f54f8e97-08cc-407b-9971-60c6cfec99dd',\n",
       " '1fd0e519-b713-4191-a708-1a6748c28a95',\n",
       " '1a80318a-2697-4cca-bf10-c26c22830a25',\n",
       " '7b7273ea-d1c6-4bdc-9f21-82f113e11ac6',\n",
       " '2867694f-d5f8-4011-b500-22cbfcc834bb',\n",
       " 'e6a16a01-2e3d-497f-8207-4549846da248',\n",
       " 'b1bfdc5b-b3dc-4265-8c38-8c33761cf2fa',\n",
       " '9e1d22cb-f0ec-4944-9404-dad748479e9b',\n",
       " '407e283c-32bc-44a5-988b-2610d6c19a8c',\n",
       " '4dc687d0-9719-4819-8418-c6fc26e32526',\n",
       " '264c4657-6da7-4044-8442-a93a3d0fe9a9',\n",
       " 'f22f493e-faaf-4ecb-9f8f-d7d6278886aa',\n",
       " '015fea0d-2005-4daa-b7c7-fcb95a4bb4a0',\n",
       " '9cbd1081-c06f-445e-a19f-2c8a5daad879',\n",
       " '8c6351f5-9e96-47d6-86fd-e30763ed8c40',\n",
       " 'f14708b0-bfc9-4172-8254-b831c28c3a2b',\n",
       " '489fe9df-7562-49d1-a829-31424e17953f',\n",
       " 'b93cb729-5e63-4c1e-8b06-2baff0ca7453',\n",
       " 'e5761845-133c-40f5-80f0-f2319a0ae471',\n",
       " '36998908-0159-4f57-8396-6120d41e3385',\n",
       " '31cbe68c-6c3f-402f-8de4-8817cc0beb4c',\n",
       " 'b01010bc-5afc-469b-9fb2-14591b8ba478',\n",
       " 'd44e2fc5-0dc6-43f2-985d-b42ac5164170',\n",
       " 'a96f9186-dea4-4637-904b-d9ac0cb0edeb',\n",
       " 'd74527da-7a6e-4f3b-9b56-9e2433e15893',\n",
       " 'b84f3ba5-f3f0-4122-98df-1029f2788c0b',\n",
       " '0544a2e7-6878-4dbf-a9a4-28f6a3c730d7',\n",
       " '6d4e838b-8ed8-4a76-80f8-1ad148c57340',\n",
       " 'a062e815-0729-4b18-8b0c-95fc7ac5f659',\n",
       " 'd310d716-a381-4485-8e00-18acfa5ac8b9',\n",
       " 'fdbdfa82-0377-427b-b169-46c2753b5a7a',\n",
       " '054268db-822e-48a2-9f06-16691dc4b1d1',\n",
       " '84e09680-a0c2-4a70-ae37-6b05cd18515c',\n",
       " '22ce0313-fb49-444b-b626-620a05a7d3e6',\n",
       " 'bbe5c94e-6a66-481d-ad15-dbcb4084be91',\n",
       " 'af59f73a-5713-4db9-9716-9baab7a64e50',\n",
       " '7e20e833-bb7f-42e9-8ddd-f3cf4a7898aa',\n",
       " 'ca737afb-e485-47eb-aa94-74bd378faa8d',\n",
       " '64724598-0a37-48af-9a77-22362557986a',\n",
       " '19093192-15f5-4bfb-a2cd-2d563c250a93',\n",
       " '413d711b-f37e-4b99-8e0d-122b8a819c54',\n",
       " '4042dfce-33ae-4b5d-9af7-db504a5bc57d',\n",
       " 'caf9c815-634c-4fb4-9220-eab278eff78f',\n",
       " 'c015cbe2-1a20-489d-926f-57b15c67034a',\n",
       " '6c710cd1-b4dc-4b52-8b8e-39cd4ead919e',\n",
       " '5b61fb28-8e3a-455a-a75f-e0c165107a78',\n",
       " '25d8884e-57fd-4fcf-bf86-ce215ffd946c',\n",
       " '3b3cc71f-447f-40f7-b88f-bd9c6ccd4b63',\n",
       " 'c5b7a757-bfe1-49a0-a99e-b1e29ef8b94f',\n",
       " 'cf182c71-54b8-413e-b5a0-57235ae665ec',\n",
       " '6734b044-293e-44a3-881f-fb0bbc2338c6',\n",
       " '050312ae-1729-427b-b8c2-bc41683925dd',\n",
       " '56477d09-0681-49e5-a839-4b461affa0c9',\n",
       " '69b0a714-d415-4bc5-bc77-6d64f8275e04',\n",
       " '6b369ed1-d245-4ca3-8a64-9483ef8bf9af',\n",
       " 'f5e1b2e9-20f2-4d7e-a6b7-5d7737c1069c',\n",
       " 'ab695a53-41f3-49ec-b821-138308e9b791',\n",
       " '658e5a4f-0689-45f1-a77e-142369fb160c',\n",
       " '477601ad-d12c-4dfd-b8af-3ae693fadd9d',\n",
       " 'c6c090a3-2e1c-4d6a-a7dc-d262df96845e',\n",
       " '2ba7e2b8-a637-49ec-847c-9fa0bf89b4f4']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28,
   "source": "elastic_vector_search.add_documents(splits)",
   "id": "4c9309d3de2ecee7"
  },
  {
   "cell_type": "markdown",
   "id": "63edbf12",
   "metadata": {},
   "source": [
    "## 🔍 Step 7: Creating a Retriever - Your Document Detective\n",
    "\n",
    "**What's a Retriever?** It's like a detective that can find the most relevant documents for any question you ask.\n",
    "\n",
    "### 🎯 Configuration:\n",
    "- **k=3**: Return the top 3 most similar documents\n",
    "- **Similarity Search**: Uses cosine similarity between query and document embeddings\n",
    "\n",
    "### 🔬 How It Works:\n",
    "1. **Your Question**: \"What happened between Milos and Ireena?\"\n",
    "2. **Query Embedding**: Converts your question to a vector\n",
    "3. **Similarity Search**: Compares your query vector to all document vectors\n",
    "4. **Top Results**: Returns the 3 most similar document chunks\n",
    "\n",
    "Let's test it and see what documents it finds!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:05:36.082750Z",
     "start_time": "2025-07-22T10:05:36.078659Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = elastic_vector_search.as_retriever(search_kwargs={\"k\": 3})",
   "id": "5c95e0b3d0d992a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "363d44a5",
   "metadata": {},
   "source": [
    "### 🧪 Testing Our Retriever\n",
    "\n",
    "Let's see what documents our retriever finds for the question \"What happened between Milos and Ireena?\"\n",
    "\n",
    "**What to look for:**\n",
    "- How many documents were retrieved?\n",
    "- Do they seem relevant to the question?\n",
    "- What kind of content is in each document?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:05:39.213908Z",
     "start_time": "2025-07-22T10:05:38.254303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = retriever.get_relevant_documents(\"What happened between Milos and Ireena?\")\n",
    "len(docs)"
   ],
   "id": "198e9387b06e8dbf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davidlapsanschi\\AppData\\Local\\Temp\\ipykernel_4812\\866813821.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"What happened between Milos and Ireena?\")\n",
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "3c47e37b",
   "metadata": {},
   "source": [
    "### 📖 Examining Retrieved Documents\n",
    "\n",
    "This will show you the actual content of the documents that were retrieved. Pay attention to:\n",
    "\n",
    "- **page_content**: The actual text content\n",
    "- **metadata**: Information about the source file, chunk position, etc.\n",
    "- **Relevance**: How well does each document match our question?\n",
    "\n",
    "This is the raw material that will be fed to our LLM to generate the final answer!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:06:14.315149Z",
     "start_time": "2025-07-22T10:06:14.309977Z"
    }
   },
   "cell_type": "code",
   "source": "docs",
   "id": "37955d2811201af6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs2\\\\Curse of Strahd.md'}, page_content=\"Meanwhile, Ireena attempts to strike up a conversation with Ez. Though well-intentioned, she soon discovers that Ez’s manner is blunt and unfiltered. Ez speaks her mind without hesitation—not out of cruelty, but because she doesn’t pause to consider how her words may land. The attempt at connection falters under the weight of Ez’s stark honesty.\\n\\nIreena approaches Milos with a heavy heart, seeking clarity after the overwhelming truths revealed during the vision within the Tome. She asks whether he managed to catch Tatyana when he leapt after her. Milos confirms that he did—and that Tatyana recognized him as Sergei.\\n\\nShe then presses further, asking what his feelings for her truly mean, especially since he had confessed his love before learning he was Sergei. Milos answers simply: he loves her. He always has, since childhood, long before his transformation into a vampire. Ireena admits that she can’t deny the emotions that surface when she looks at him—but she’s not in a place where she can unravel them.\\n\\nMilos reflects aloud, uncertain whether his feelings stem from the fragment of Sergei's soul within him or from his love for Ireena herself. She echoes the same doubt, wondering whether what they feel is genuine or merely the result of fate or the Dark Powers manipulating them.\\n\\nIreena proposes they make a pact: to see each other as individuals, not as echoes of Tatyana and Sergei. Milos agrees, adding that he loved her before he knew who they once were. Ireena admits the same—but explains that it’s hard to feel anything clearly now. She’s unsure whether Milos has buried parts of himself beneath his anger, or if those parts are simply gone.\\n\\nMilos confesses he has endured more than he can name. He doesn’t know if he will ever be the man he once was, but he is trying to discover who he wants to become. Ireena assures him she holds no judgment for the path he took; she would never condemn someone for making a different choice.\"),\n",
       " Document(metadata={'source': 'docs2\\\\Curse of Strahd.md'}, page_content=\"Milos nods, his voice trembling as he reflects on his past. He acknowledges that, before the drinking, Laszlo hadn’t been a bad father. It was different when he was a child, and there had been moments of tenderness between them. But the rage and the alcohol had driven a wedge between them, one that Milos had never been able to overcome.\\n\\nHe also admits that this past year has changed him. He’s done things he’s not proud of, and in the process, he’s become something he despises—a monster. But despite everything, Milos vows that he will do whatever it takes to make things right, even if it means becoming a tool for Lathander’s will.\\n\\nIreena looks at him with a mixture of sympathy and strength. She shares her own struggles, revealing that she, too, is a tool of fate—one that has often been cruel and unforgiving. But she doesn’t care about that anymore. What matters is taking control of her own fate, and Milos must do the same.\\n\\nOvercome with emotion, Milos breaks down, tears flowing freely. Ireena steps forward and envelops him in a comforting embrace. In that moment, the weight of the world seems to lift, if only for a brief moment. She whispers softly, assuring him that they will help each other become better—one step at a time.\\n\\nAt the Burgomaster's house, while the party rests, Ireena and Izmark catch up. Ireena shares the details of our journey so far, though she carefully omits the secret of being the key to the curse and Tatyana’s reincarnation. As the conversation shifts to our next course of action, the party agrees that digging up whatever Victor and the elf had buried is our priority.\"),\n",
       " Document(metadata={'source': 'docs2\\\\Curse of Strahd.md'}, page_content=\"Their conversation shifts naturally, landing on the subject of Milos’s vampirism. He confesses that he never wanted this existence and has no intention of living as a creature of the night. Ireena asks if he would accept a cure, should one ever become possible. Milos admits he would—he does not wish to live this way.\\n\\nIn the stillness before the vision ends, Ireena invites him to dance. As they move together, Milos confesses his love for her. The words stun her into silence. She looks at him, at the way he smiles, and murmurs that she remembers a time when he used to smile like that.\\n\\nMeanwhile, Ziva finds Arabelle and gently inquires about her reaction earlier—when Strahd spoke and Arabelle froze before hiding behind her. Arabelle reveals that she saw memories from Strahd’s perspective, visions she cannot bring herself to speak of just yet.\\n\\nZiva assures Arabelle that she will always be there whenever Arabelle feels ready to talk. Arabelle offers a quick thank-you, then shifts the conversation. She asks whether, if she were to stop traveling with the party, they would still visit her. Ziva responds without hesitation, affirming that they would.\\n\\nThis leads Arabelle to wonder aloud whether Milos might leave Moonshade to stay with her. Ziva considers the idea and admits it’s possible. She agrees with Arabelle's sentiment—that Milos can be both incredibly frustrating and unexpectedly kind.\\n\\nAt this, Arabelle presses further, asking what Ziva’s connection with Milos truly is. Ziva tries to deflect the question, but ultimately admits that she likes him as a person. Still, she insists that she holds no romantic feelings for him.\\n\\nWith that, they rejoin the group in the chapel hall, at about the same time that Ireena and Milos do.\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "05b0775d",
   "metadata": {},
   "source": [
    "## 🎭 Step 8: Crafting the Perfect RAG Prompt\n",
    "\n",
    "**Why Custom Prompts Matter**: The prompt is like giving instructions to a human assistant. Good prompts = better answers!\n",
    "\n",
    "### 🎯 Our Prompt Strategy:\n",
    "1. **Role Definition**: \"You are a Dungeon Master's assistant\" - sets context\n",
    "2. **Task Clarity**: Explains what the context is and how to use it\n",
    "3. **Constraints**: \"Don't make up answers\" - prevents hallucination\n",
    "4. **Response Format**: \"Limit to 5 sentences\" - keeps answers focused\n",
    "5. **Personality**: \"Thanks for asking!\" - adds character\n",
    "\n",
    "### 💡 Prompt Engineering Tips:\n",
    "- **Be Specific**: Clear instructions produce better results\n",
    "- **Set Boundaries**: Tell the model what NOT to do\n",
    "- **Add Context**: Help the model understand its role\n",
    "- **Format Expectations**: Specify desired output format\n",
    "\n",
    "This prompt will transform raw document chunks into helpful, accurate answers!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:06:19.893609Z",
     "start_time": "2025-07-22T10:06:19.836656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are Dungeon Master's assistant for the Curse of Strahd campaign.\n",
    "The context you will receive will be pieces of information taken from the notes taken after every session.\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Include all relevant information but limit the response to 5 sentences.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ],
   "id": "c7d1f5641876cf65",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "534fc4fb",
   "metadata": {},
   "source": [
    "### 🔧 Document Formatting Helper\n",
    "\n",
    "This simple but crucial function takes our retrieved documents and formats them for the LLM:\n",
    "\n",
    "- **Combines Multiple Docs**: Joins all retrieved documents into one context\n",
    "- **Clean Separation**: Uses `\\n\\n` to clearly separate different documents\n",
    "- **Context Preparation**: Prepares the \"context\" variable for our prompt template\n",
    "\n",
    "Without this, we'd just have a list of document objects. With it, we have clean, formatted text that the LLM can understand and use!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:06:22.031091Z",
     "start_time": "2025-07-22T10:06:22.026259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ],
   "id": "21914c9b2895c5ad",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "4a9d7fcc",
   "metadata": {},
   "source": [
    "## ⛓️ Step 9: Building the Complete RAG Chain\n",
    "\n",
    "**This is where everything comes together!** We're building a processing pipeline that:\n",
    "\n",
    "### 🔄 The RAG Chain Flow:\n",
    "1. **Input**: User question (e.g., \"What happened between Milos and Ireena?\")\n",
    "2. **Retrieve**: `retriever` finds relevant documents\n",
    "3. **Format**: `format_docs` prepares them for the LLM\n",
    "4. **Prompt**: `custom_rag_prompt` creates the final prompt with context\n",
    "5. **Generate**: `llm` creates the answer\n",
    "6. **Parse**: `StrOutputParser` extracts just the text response\n",
    "\n",
    "### 🧩 LangChain Magic:\n",
    "- **`|` Symbol**: Chains components together (like Unix pipes)\n",
    "- **`RunnablePassthrough()`**: Passes the original question through unchanged\n",
    "- **Dictionary Structure**: Provides both `context` and `question` to the prompt\n",
    "\n",
    "**Result**: A complete RAG system in just a few lines of code!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:07:39.692351Z",
     "start_time": "2025-07-22T10:07:39.687477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | custom_rag_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ],
   "id": "38b63bb7618d5c66",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "9874f80d",
   "metadata": {},
   "source": [
    "### 🎉 Testing Our Basic RAG System!\n",
    "\n",
    "**The Moment of Truth!** Let's test our complete RAG system with the same question we asked the LLM earlier.\n",
    "\n",
    "**Compare the results:**\n",
    "- **Before RAG**: Model didn't know about Milos and Ireena\n",
    "- **After RAG**: Model should provide specific information from our campaign notes\n",
    "\n",
    "**What to expect:**\n",
    "- A focused, relevant answer based on retrieved documents\n",
    "- Information that wasn't in the model's training data\n",
    "- The signature \"thanks for asking!\" at the end\n",
    "\n",
    "This demonstrates the **core power of RAG**: extending AI knowledge with your own data!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:07:44.018317Z",
     "start_time": "2025-07-22T10:07:41.530973Z"
    }
   },
   "cell_type": "code",
   "source": "rag_chain.invoke(\"What happened between Milos and Ireena?\")",
   "id": "9487b8762a055d88",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Milos and Ireena shared a deeply emotional and honest conversation about their complicated feelings, shaped by their pasts and the echoes of Sergei and Tatyana. Milos confessed his love for Ireena, which he says has existed since childhood, before his transformation into a vampire, though both question whether their feelings are genuine or influenced by fate or the Dark Powers. They agreed to see each other as individuals rather than as reincarnations, acknowledging the difficulty in untangling their emotions. Milos broke down emotionally, and Ireena comforted him, promising mutual support as they try to become better people. Later, Milos also expressed a desire for a cure to his vampirism, showing his hope for redemption. Thanks for asking!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "6906663d",
   "metadata": {},
   "source": [
    "## 🚀 Step 10: Enhanced RAG - Query Rewriting\n",
    "\n",
    "**Problem**: Sometimes users ask questions in ways that don't match how information is stored in documents.\n",
    "\n",
    "**Solution**: **Query Rewriting** - Transform user queries into better search terms!\n",
    "\n",
    "### 🔄 How Query Rewriting Works:\n",
    "1. **User Question**: \"What are Sally's abilities?\" (might be too vague)\n",
    "2. **LLM Rewriting**: \"What are Sally's magical powers, combat skills, and special abilities in the Curse of Strahd campaign?\"\n",
    "3. **Better Retrieval**: More specific query = better document matches\n",
    "4. **Better Answers**: More relevant context = higher quality responses\n",
    "\n",
    "### 💡 Why This Helps:\n",
    "- **Bridges Language Gap**: User casual language → Document formal language\n",
    "- **Adds Context**: Includes domain-specific terms (D&D, Curse of Strahd)\n",
    "- **Improves Specificity**: Vague questions become detailed queries\n",
    "- **Better Matching**: Embedding similarity improves with better queries"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:08:29.431556Z",
     "start_time": "2025-07-22T10:08:29.427292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rewrite_template = \"\"\"Rewrite the provided user query to be optimized for RAG retrieval knowing the user query is related to a Curse of Strahd campaign and what happened during the campaign.\n",
    "Make sure it's detailed enough to facilitate retrieval of data from the vector store.\n",
    "\n",
    "User query: {question}\n",
    "\n",
    "Rewritten user query:\"\"\"\n",
    "rewrite_query_prompt = PromptTemplate.from_template(rewrite_template)"
   ],
   "id": "6a3614a3773a153a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "4c2f63bc",
   "metadata": {},
   "source": [
    "# Advanced RAG Implementation with Multiple Techniques\n",
    "\n",
    "This notebook demonstrates three levels of RAG (Retrieval Augmented Generation) implementation:\n",
    "\n",
    "1. **Basic RAG**: Simple query → retrieve documents → generate answer\n",
    "2. **Enhanced RAG**: Query rewriting → retrieve documents → generate answer\n",
    "3. **Advanced RAG**: Query decomposition → multiple retrievals → deduplicate → generate answer\n",
    "\n",
    "The advanced RAG implementation breaks down complex queries into multiple sub-questions, retrieves documents for each sub-question, deduplicates the results, and then generates a comprehensive answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e4377",
   "metadata": {},
   "source": [
    "### 🧪 Testing Query Rewriting\n",
    "\n",
    "Let's see how our query rewriting system transforms user questions into better search queries.\n",
    "\n",
    "**Original vs Rewritten**: Notice how the rewritten query:\n",
    "- Adds relevant context (D&D, Curse of Strahd)\n",
    "- Uses more specific terminology\n",
    "- Provides better search targets for our vector store"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:08:35.507406Z",
     "start_time": "2025-07-22T10:08:34.592230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a query rewriting step\n",
    "rewrite_chain = rewrite_query_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Test the rewrite chain\n",
    "original_query = \"What happened between Milos and Ireena?\"\n",
    "rewritten_query = rewrite_chain.invoke({\"question\": original_query})\n",
    "print(f\"Original: {original_query}\")\n",
    "print(f\"Rewritten: {rewritten_query}\")"
   ],
   "id": "6556c86e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: What happened between Milos and Ireena?\n",
      "Rewritten: In the Curse of Strahd campaign, what are the key events and interactions that occurred between the characters Milos and Ireena? Please provide detailed information about their relationship, significant encounters, conflicts, or alliances throughout the storyline.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "ca80146e",
   "metadata": {},
   "source": [
    "### 🔗 Building the Enhanced RAG Chain\n",
    "\n",
    "Now we're creating an **enhanced RAG system** that automatically rewrites queries before retrieval:\n",
    "\n",
    "**Enhanced Flow:**\n",
    "1. **User Query** → 2. **Query Rewriting** → 3. **Document Retrieval** → 4. **Answer Generation**\n",
    "\n",
    "**Key Changes:**\n",
    "- `enhanced_retriever()`: First rewrites the query, then retrieves documents\n",
    "- `lambda query:`: Anonymous function that processes the query through our enhancement pipeline\n",
    "\n",
    "**Benefits:**\n",
    "- Automatic query optimization\n",
    "- No extra work for users\n",
    "- Better retrieval results\n",
    "- More accurate answers"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:08:52.348517Z",
     "start_time": "2025-07-22T10:08:52.342825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the enhanced RAG chain with query rewriting\n",
    "def enhanced_retriever(query):\n",
    "    # First rewrite the query\n",
    "    rewritten_query = rewrite_chain.invoke({\"question\": query})\n",
    "    # Then use the rewritten query to retrieve documents\n",
    "    return retriever.get_relevant_documents(rewritten_query)\n",
    "\n",
    "# Build the complete RAG chain with query rewriting\n",
    "enhanced_rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda query: format_docs(enhanced_retriever(query)),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "2f39d9b6",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "8cdd4fdb",
   "metadata": {},
   "source": [
    "### 🏁 Enhanced vs Basic RAG Comparison\n",
    "\n",
    "Let's compare our **Enhanced RAG** (with query rewriting) against our **Basic RAG** system:\n",
    "\n",
    "**What to Look For:**\n",
    "- **Answer Quality**: Are the enhanced answers more detailed or accurate?\n",
    "- **Relevance**: Does enhanced RAG find better source material?\n",
    "- **Completeness**: Does query rewriting help find more comprehensive information?\n",
    "\n",
    "**Expected Results:**\n",
    "- Enhanced RAG should provide more contextual and complete answers\n",
    "- The rewritten query should retrieve more relevant documents\n",
    "- Overall answer quality should improve significantly"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:09:02.231136Z",
     "start_time": "2025-07-22T10:08:57.152547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the enhanced RAG chain\n",
    "query = \"What are Sally's abilities?\"\n",
    "print(\"Testing enhanced RAG chain with query rewriting:\")\n",
    "enhanced_response = enhanced_rag_chain.invoke(query)\n",
    "print(enhanced_response)\n",
    "\n",
    "# Compare with the original chain\n",
    "print(\"\\nComparing with original RAG chain:\")\n",
    "original_response = rag_chain.invoke(query)\n",
    "print(original_response)"
   ],
   "id": "6bae5b6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing enhanced RAG chain with query rewriting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sally has the ability to transform into a spider, as demonstrated when she investigates the inn in her spider form. She can also cast Detect Magic, which she uses to sense faint magical presences. Additionally, she experiences visions through a raven, which show her prophetic and symbolic scenes related to Strahd and the land's decay. Sally has a mysterious black wound above her right shoulder that sometimes oozes smoke and never fully heals, hinting at a supernatural or cursed nature. Her upbringing among druids and nature-loving people suggests a connection to nature and possibly druidic or magical abilities. Thanks for asking!\n",
      "\n",
      "Comparing with original RAG chain:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sally has the ability to transform into powerful animal forms, such as a massive constrictor snake, an elk, and a giant eagle, showcasing her strong connection to nature and shapeshifting prowess. She can summon and bond with natural creatures, like the elk she calls forth in battle. Sally also possesses radiant soul wings that glow with divine light, allowing her to engage in aerial combat and flight. Her magic is distinct from divine intervention, as Madame Eva points out, emphasizing that Sally’s power comes from a deep, personal connection to nature rather than relying on gods. Additionally, Sally can sense and communicate with the natural world on a profound level, feeling the suffering of a dying tree and understanding its plight. Thanks for asking!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "f0e77530",
   "metadata": {},
   "source": [
    "## 🎓 Step 11: Advanced RAG - Query Decomposition\n",
    "\n",
    "**The Problem**: Complex questions often need information from multiple sources. Single queries might miss important context.\n",
    "\n",
    "**The Solution**: **Query Decomposition** - Break complex questions into multiple focused sub-questions!\n",
    "\n",
    "### 🧩 How Query Decomposition Works:\n",
    "\n",
    "1. **Complex Question**: \"What are key moments between Ziva and Milos?\"\n",
    "2. **Decompose**: Break into 3-5 focused sub-questions:\n",
    "   - \"Who is Ziva in the Curse of Strahd campaign?\"\n",
    "   - \"Who is Milos and what role does he play?\"\n",
    "   - \"What interactions occurred between Ziva and Milos?\"\n",
    "   - \"What significant events involved both characters?\"\n",
    "3. **Multi-Retrieval**: Search documents for each sub-question\n",
    "4. **Deduplicate**: Remove duplicate documents\n",
    "5. **Comprehensive Answer**: Generate response with broader context\n",
    "\n",
    "### 🎯 Benefits:\n",
    "- **Comprehensive Coverage**: Captures multiple aspects of complex questions\n",
    "- **Better Context**: More diverse document retrieval\n",
    "- **Reduced Blind Spots**: Harder to miss relevant information\n",
    "- **Robust Answers**: Well-rounded responses to nuanced queries"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:09:45.912667Z",
     "start_time": "2025-07-22T10:09:45.907802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "# Create a prompt for decomposing the query into multiple sub-questions\n",
    "decompose_query_template = \"\"\"Break down the following question into 3-5 clear and simple sub-questions that would help gather relevant information to answer the main question comprehensively knowing the main question is related to a Curse of Strahd D&D campaign and what happened during that campaign.\n",
    "Think step-by-step about what information would be needed to provide a complete answer.\n",
    "\n",
    "Main question: {question}\n",
    "\n",
    "Generate 3-5 sub-questions, each on a new line, prefixed with \"Q: \".\n",
    "Do not number the questions, just prefix with Q:.\n",
    "\n",
    "Sub-questions:\"\"\"\n",
    "\n",
    "decompose_query_prompt = PromptTemplate.from_template(decompose_query_template)\n",
    "\n",
    "# Chain to decompose a query into multiple sub-questions\n",
    "decompose_chain = decompose_query_prompt | llm | StrOutputParser()"
   ],
   "id": "f2fa77a2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "e52758a4",
   "metadata": {},
   "source": [
    "### 🔍 Multi-Query Retrieval Implementation\n",
    "\n",
    "This is the **heart of our Advanced RAG system**. Here's what this complex function does:\n",
    "\n",
    "### 🔄 Step-by-Step Process:\n",
    "\n",
    "1. **Query Decomposition**: \n",
    "   - Takes complex question and breaks it into 3-5 sub-questions\n",
    "   - Each sub-question focuses on a specific aspect\n",
    "\n",
    "2. **Enhanced Retrieval**: \n",
    "   - For each sub-question, first rewrites it (query enhancement)\n",
    "   - Then retrieves relevant documents\n",
    "   - Combines benefits of both enhancement techniques\n",
    "\n",
    "3. **Document Collection**: \n",
    "   - Gathers all documents from all sub-queries\n",
    "   - Results in a comprehensive document pool\n",
    "\n",
    "4. **Deduplication**: \n",
    "   - Removes duplicate documents (using first 100 characters as key)\n",
    "   - Prevents redundant information in final context\n",
    "\n",
    "5. **Optimization**: \n",
    "   - Limits to maximum documents (default 8) to stay within LLM context limits\n",
    "   - Returns most relevant, non-duplicate documents\n",
    "\n",
    "**Result**: A rich, diverse set of documents that covers multiple aspects of the original complex question!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:09:49.977215Z",
     "start_time": "2025-07-22T10:09:49.967313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to parse sub-questions from the decompose chain output\n",
    "def parse_sub_questions(decompose_output: str) -> List[str]:\n",
    "    \"\"\"Parse the output from the decompose chain into a list of sub-questions.\"\"\"\n",
    "    lines = decompose_output.strip().split('\\n')\n",
    "    questions = [line[3:].strip() for line in lines if line.startswith('Q:')]\n",
    "    return questions\n",
    "\n",
    "# Function to retrieve documents for a list of questions and combine results\n",
    "def multi_query_retriever(query: str, max_docs: int = 8) -> List:\n",
    "    \"\"\"\n",
    "    Break down a query into sub-questions, retrieve documents for each, and combine results.\n",
    "\n",
    "    Args:\n",
    "        query: The main user query\n",
    "        max_docs: Maximum number of documents to return (after deduplication)\n",
    "\n",
    "    Returns:\n",
    "        List of retrieved documents\n",
    "    \"\"\"\n",
    "    # Decompose the main query into sub-questions\n",
    "    decomposed_output = decompose_chain.invoke({\"question\": query})\n",
    "    sub_questions = parse_sub_questions(decomposed_output)\n",
    "\n",
    "    print(f\"Main query: {query}\")\n",
    "    print(f\"Decomposed into {len(sub_questions)} sub-questions:\")\n",
    "    for i, q in enumerate(sub_questions):\n",
    "        print(f\"{i+1}. {q}\")\n",
    "\n",
    "    # Retrieve documents for each sub-question\n",
    "    all_docs = []\n",
    "    for sub_q in sub_questions:\n",
    "        # Option 1: Use the original retriever\n",
    "        # docs = retriever.get_relevant_documents(sub_q)\n",
    "\n",
    "        # Option 2: Use the enhanced retriever with query rewriting\n",
    "        rewritten_sub_q = rewrite_chain.invoke({\"question\": sub_q})\n",
    "        docs = retriever.get_relevant_documents(rewritten_sub_q)\n",
    "\n",
    "        print(f\"Retrieved {len(docs)} docs for: '{sub_q}'\")\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    # Deduplicate documents based on document content\n",
    "    unique_docs = []\n",
    "    unique_contents = set()\n",
    "\n",
    "    for doc in all_docs:\n",
    "        # Use the first 100 chars as a simple deduplication key\n",
    "        # In a production system, you'd want a more robust deduplication strategy\n",
    "        content_key = doc.page_content[:100]\n",
    "        if content_key not in unique_contents:\n",
    "            unique_contents.add(content_key)\n",
    "            unique_docs.append(doc)\n",
    "\n",
    "    print(f\"Total documents before deduplication: {len(all_docs)}\")\n",
    "    print(f\"Total documents after deduplication: {len(unique_docs)}\")\n",
    "\n",
    "    # Limit to max_docs\n",
    "    final_docs = unique_docs[:max_docs] if len(unique_docs) > max_docs else unique_docs\n",
    "    print(f\"Returning {len(final_docs)} documents\")\n",
    "\n",
    "    return final_docs"
   ],
   "id": "1e985684",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "2f068441",
   "metadata": {},
   "source": [
    "### ⛓️ Advanced RAG Chain Assembly\n",
    "\n",
    "Creating our most sophisticated RAG system yet! This chain combines:\n",
    "\n",
    "**All Three Techniques:**\n",
    "1. **Query Decomposition**: Breaks complex questions into focused sub-questions\n",
    "2. **Query Rewriting**: Optimizes each sub-question for better retrieval\n",
    "3. **Multi-Document Retrieval**: Gathers comprehensive context from multiple searches\n",
    "\n",
    "**Complete Flow:**\n",
    "User Question → Decompose → Rewrite Sub-Questions → Multi-Retrieval → Deduplicate → Format → Generate Answer\n",
    "\n",
    "This represents the **state-of-the-art** in RAG systems!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:09:53.209425Z",
     "start_time": "2025-07-22T10:09:53.205209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the advanced RAG chain with query decomposition\n",
    "advanced_rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda query: format_docs(multi_query_retriever(query)),\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "4301a89a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "7fb034c4",
   "metadata": {},
   "source": [
    "## 🏆 The Ultimate RAG Showdown!\n",
    "\n",
    "Time for the **final comparison**! We'll test all three RAG implementations with the same complex question:\n",
    "\n",
    "### 🥊 The Contestants:\n",
    "\n",
    "1. **🥉 Basic RAG**: Simple query → retrieve → answer\n",
    "2. **🥈 Enhanced RAG**: Query rewriting → retrieve → answer  \n",
    "3. **🥇 Advanced RAG**: Query decomposition → multiple rewrites → multi-retrieve → deduplicate → answer\n",
    "\n",
    "### 📊 What to Compare:\n",
    "\n",
    "- **Answer Completeness**: Which provides the most comprehensive response?\n",
    "- **Information Quality**: Which finds the most relevant details?\n",
    "- **Processing Transparency**: Notice how Advanced RAG shows its thinking process\n",
    "- **Context Richness**: Which system gathers the best supporting evidence?\n",
    "\n",
    "**Hypothesis**: Advanced RAG should provide the most complete and nuanced answer because it:\n",
    "- Considers multiple aspects of the question\n",
    "- Retrieves more diverse documents\n",
    "- Combines information from various sources\n",
    "\n",
    "Let's see the results! 🎬"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T10:10:11.600572Z",
     "start_time": "2025-07-22T10:09:56.917547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the advanced RAG chain with query decomposition\n",
    "complex_query = \"What are key moments between Ziva and Milos?\"\n",
    "\n",
    "print(\"TESTING ADVANCED RAG CHAIN WITH QUERY DECOMPOSITION:\")\n",
    "advanced_response = advanced_rag_chain.invoke(complex_query)\n",
    "print(\"\\nAdvanced RAG Chain Response:\")\n",
    "print(advanced_response)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "print(\"\\nCOMPARING WITH ENHANCED RAG CHAIN:\")\n",
    "enhanced_response = enhanced_rag_chain.invoke(complex_query)\n",
    "print(\"\\nEnhanced RAG Chain Response (with query rewriting only):\")\n",
    "print(enhanced_response)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "print(\"\\nCOMPARING WITH ORIGINAL RAG CHAIN:\")\n",
    "original_response = rag_chain.invoke(complex_query)\n",
    "print(\"\\nOriginal RAG Chain Response:\")\n",
    "print(original_response)"
   ],
   "id": "ec119eaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ADVANCED RAG CHAIN WITH QUERY DECOMPOSITION:\n",
      "Main query: What are key moments between Ziva and Milos?\n",
      "Decomposed into 5 sub-questions:\n",
      "1. What are the backgrounds and motivations of Ziva and Milos in the Curse of Strahd campaign?\n",
      "2. How did Ziva and Milos first meet and what was their initial relationship like?\n",
      "3. What significant events or challenges did Ziva and Milos face together during the campaign?\n",
      "4. Were there any turning points or conflicts between Ziva and Milos that affected their relationship?\n",
      "5. How did the interactions between Ziva and Milos influence the overall story or outcome of the campaign?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 docs for: 'What are the backgrounds and motivations of Ziva and Milos in the Curse of Strahd campaign?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 docs for: 'How did Ziva and Milos first meet and what was their initial relationship like?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 docs for: 'What significant events or challenges did Ziva and Milos face together during the campaign?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 docs for: 'Were there any turning points or conflicts between Ziva and Milos that affected their relationship?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 docs for: 'How did the interactions between Ziva and Milos influence the overall story or outcome of the campaign?'\n",
      "Total documents before deduplication: 15\n",
      "Total documents after deduplication: 6\n",
      "Returning 6 documents\n",
      "\n",
      "Advanced RAG Chain Response:\n",
      "Key moments between Ziva and Milos include their complex dynamic where Ziva is intrigued by Milos despite his many red flags, and she even considers making a move on him while acknowledging the complications it would bring. They share a bond over their faith in the Morninglord, with Ziva encouraging Milos to find his own spiritual clarity despite Barovia’s darkness. Ziva and Milos also have candid conversations about power and their pasts, including Milos’ vampirism and his painful history with Strahd. Their relationship is marked by a mix of cautious respect and underlying tension, as Milos admits he trusts only Ireena fully and views others, including Ziva, as tools to be used if necessary. Additionally, Ziva openly admits liking Milos as a person but denies romantic feelings, highlighting the nuanced nature of their connection. Thanks for asking!\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "COMPARING WITH ENHANCED RAG CHAIN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced RAG Chain Response (with query rewriting only):\n",
      "Key moments between Ziva and Milos include Ziva considering making a move on Milos despite acknowledging his many red flags and the complicated situation they are already in. Ziva admits to liking Milos as a person but insists she has no romantic feelings for him, even as Arabelle questions their connection. Ziva congratulates Sergei on his fight with Milos, bonding over shared values, which indirectly ties her to Milos’s circle. Arabelle wonders if Milos might leave Moonshade to stay with her, and Ziva agrees it’s possible, showing her awareness of Milos’s complicated relationships. Throughout, Ziva’s attitude toward Milos is one of intrigue mixed with caution, highlighting a nuanced dynamic. Thanks for asking!\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "COMPARING WITH ORIGINAL RAG CHAIN:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\evo-rag\\Evo-rag-workshop\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original RAG Chain Response:\n",
      "Key moments between Ziva and Milos include their shared swim in the frozen lake, which serves as a quiet bonding experience after Ziva’s breakdown. Ziva reveals her complicated past involving a childhood crush and betrayal, showing vulnerability to the group. She also expresses interest in Milos romantically, considering making a move on him despite the complicated situation. Ziva and Arabelle discuss Milos’s potential future, with Ziva admitting she likes him as a person but denies romantic feelings, highlighting the complexity of their relationship. Throughout, Ziva supports Milos emotionally, indicating a growing connection beyond mere acquaintances. Thanks for asking!\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7c1236d9c96e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1bd395",
   "metadata": {},
   "source": [
    "## 🎓 Workshop Conclusion: Your RAG Journey\n",
    "\n",
    "Congratulations! You've built and understood three levels of RAG systems. Let's recap what you've learned:\n",
    "\n",
    "### 🚀 Your RAG Evolution:\n",
    "\n",
    "#### 1. **Basic RAG** - The Foundation\n",
    "- ✅ **Core Concept**: Retrieve documents → Generate answers\n",
    "- ✅ **Vector Embeddings**: Convert text to searchable numbers\n",
    "- ✅ **Similarity Search**: Find relevant content automatically\n",
    "- ✅ **Prompt Engineering**: Craft effective instructions for LLMs\n",
    "\n",
    "#### 2. **Enhanced RAG** - Query Optimization\n",
    "- ✅ **Query Rewriting**: Transform user questions for better retrieval\n",
    "- ✅ **Domain Context**: Add specialized knowledge to queries\n",
    "- ✅ **Improved Matching**: Better queries = better document retrieval\n",
    "\n",
    "#### 3. **Advanced RAG** - Multi-Dimensional Retrieval\n",
    "- ✅ **Query Decomposition**: Break complex questions into focused parts\n",
    "- ✅ **Multi-Retrieval**: Search multiple aspects simultaneously\n",
    "- ✅ **Deduplication**: Optimize document selection\n",
    "- ✅ **Comprehensive Answers**: Rich, nuanced responses\n",
    "\n",
    "### 🎯 Key Takeaways for Real-World Applications:\n",
    "\n",
    "1. **Start Simple**: Basic RAG solves 80% of use cases effectively\n",
    "2. **Iterate & Improve**: Add complexity only when needed\n",
    "3. **Domain Knowledge Matters**: Custom prompts and context are crucial\n",
    "4. **Quality Over Quantity**: Better retrieval > more documents\n",
    "5. **User Experience**: Complex systems should feel simple to users\n",
    "\n",
    "### 🚀 Next Steps in Your RAG Journey:\n",
    "\n",
    "- **Experiment with Different Embedding Models**: Try domain-specific embeddings\n",
    "- **Explore Hybrid Search**: Combine semantic + keyword search\n",
    "- **Add Evaluation Metrics**: Measure and improve your RAG system\n",
    "- **Consider Production Concerns**: Scaling, latency, cost optimization\n",
    "- **Advanced Techniques**: Graph RAG, Agentic RAG, Multi-modal RAG\n",
    "\n",
    "### 📚 Production Considerations:\n",
    "\n",
    "- **Cost Management**: Embedding and LLM API calls add up\n",
    "- **Latency Optimization**: Users expect fast responses\n",
    "- **Data Privacy**: Ensure sensitive information is handled properly\n",
    "- **Evaluation & Monitoring**: Continuously measure and improve performance\n",
    "\n",
    "**Remember**: The best RAG system is the one that solves your users' problems effectively and efficiently. Start with the basics, understand your users' needs, then evolve your system accordingly.\n",
    "\n",
    "Thanks for joining this RAG workshop! 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
