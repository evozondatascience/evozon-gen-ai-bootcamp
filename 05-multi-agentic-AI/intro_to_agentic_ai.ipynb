{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb553913418b60a",
   "metadata": {},
   "source": [
    "# Introduction to Multi Agentic AI\n",
    "\n",
    "Welcome to this hands-on workshop on Agentic AI systems. In this session, you'll learn how to build an intelligent AI fashion assistant that demonstrates key concepts of agentic behavior.\n",
    "\n",
    "## What You'll Add\n",
    "\n",
    "An AI agent that can:\n",
    "- Generate images with a chosen wardrobe\n",
    "- Maintain conversation context across multiple interactions\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "This workshop focuses on building **agents** rather than simple chatbots. By the end, you'll understand how to create AI systems that can:\n",
    "\n",
    "1. **Take advantage of** human in the loop for feedback.\n",
    "2. **Make decisions** based on combined data inputs\n",
    "3. **Talk with other agents** and give feedback\n",
    "3. **Remember context** across multiple conversation turns\n",
    "4. **Reason through multi-step processes** to complete complex tasks\n",
    "\n",
    "## Key Concepts Covered\n",
    "\n",
    "- Human in the loop\n",
    "- Multi agentic architectures\n",
    "- Persistent memory systems\n",
    "- Graph-based agent architectures\n",
    "\n",
    "Let's begin by installing the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T12:34:34.841247Z",
     "start_time": "2025-07-28T12:33:46.276849Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-core==0.3.69 (from -r ./requirements.txt (line 1))\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-openai==0.3.28 (from -r ./requirements.txt (line 2))\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-community==0.3.27 (from -r ./requirements.txt (line 3))\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-text-splitters==0.3.8 (from -r ./requirements.txt (line 4))\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchainhub==0.1.21 (from -r ./requirements.txt (line 5))\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting unstructured==0.18.9 (from -r ./requirements.txt (line 6))\n",
      "  Downloading unstructured-0.18.9-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting markdown==3.8.2 (from -r ./requirements.txt (line 7))\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting elasticsearch==8.18.1 (from -r ./requirements.txt (line 8))\n",
      "  Downloading elasticsearch-8.18.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting langchain-elasticsearch==0.3.2 (from -r ./requirements.txt (line 9))\n",
      "  Downloading langchain_elasticsearch-0.3.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting streamlit==1.39.0 (from -r ./requirements.txt (line 10))\n",
      "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langgraph==0.5.4 (from -r ./requirements.txt (line 11))\n",
      "  Downloading langgraph-0.5.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading langsmith-0.4.8-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from langchain-core==0.3.69->-r ./requirements.txt (line 1)) (25.0)\n",
      "Collecting pydantic>=2.7.4 (from langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting openai<2.0.0,>=1.86.0 (from langchain-openai==0.3.28->-r ./requirements.txt (line 2))\n",
      "  Downloading openai-1.97.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.3.28->-r ./requirements.txt (line 2))\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.26 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from langchain-community==0.3.27->-r ./requirements.txt (line 3)) (2.32.4)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting packaging>=23.2 (from langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.21->-r ./requirements.txt (line 5))\n",
      "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting chardet (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting nltk (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (4.13.4)\n",
      "Collecting emoji (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------------------------------- 981.5/981.5 kB 11.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting unstructured-client (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading unstructured_client-0.41.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting wrapt (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting tqdm (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from unstructured==0.18.9->-r ./requirements.txt (line 6)) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch==8.18.1->-r ./requirements.txt (line 8))\n",
      "  Downloading elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: python-dateutil in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (2.9.0.post0)\n",
      "Collecting altair<6,>=4.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<11,>=7.1.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from streamlit==1.39.0->-r ./requirements.txt (line 10)) (6.5.1)\n",
      "Collecting watchdog<6,>=2.1.5 (from streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading watchdog-5.0.3-py3-none-win_amd64.whl.metadata (41 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph==0.5.4->-r ./requirements.txt (line 11))\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph==0.5.4->-r ./requirements.txt (line 11))\n",
      "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.5.4->-r ./requirements.txt (line 11))\n",
      "  Downloading langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph==0.5.4->-r ./requirements.txt (line 11))\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (4.25.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading narwhals-2.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (2.5.0)\n",
      "Requirement already satisfied: certifi in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (2025.7.14)\n",
      "Collecting simsimd>=3 (from elasticsearch[vectorstore-mmr]<9.0.0,>=8.13.1->langchain-elasticsearch==0.3.2->-r ./requirements.txt (line 9))\n",
      "  Downloading simsimd-6.5.0-cp312-cp312-win_amd64.whl.metadata (72 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.69->-r ./requirements.txt (line 1)) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain<1.0.0,>=0.3.26 (from langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.5.4->-r ./requirements.txt (line 11))\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.5.4->-r ./requirements.txt (line 11)) (0.28.1)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.5.4->-r ./requirements.txt (line 11))\n",
      "  Downloading orjson-3.11.1-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2))\n",
      "  Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai==0.3.28->-r ./requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.5.4->-r ./requirements.txt (line 11)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.5.4->-r ./requirements.txt (line 11)) (0.16.0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.27->-r ./requirements.txt (line 3)) (3.4.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (2.19.2)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading greenlet-3.2.3-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.3.28->-r ./requirements.txt (line 2))\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.27->-r ./requirements.txt (line 3))\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.39.0->-r ./requirements.txt (line 10)) (0.26.0)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.3.45->langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core==0.3.69->-r ./requirements.txt (line 1))\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.39.0->-r ./requirements.txt (line 10))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from python-dateutil->elasticsearch==8.18.1->-r ./requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from beautifulsoup4->unstructured==0.18.9->-r ./requirements.txt (line 6)) (2.7)\n",
      "Requirement already satisfied: webencodings in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from html5lib->unstructured==0.18.9->-r ./requirements.txt (line 6)) (0.5.1)\n",
      "Collecting joblib (from nltk->unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.6.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6))\n",
      "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\projects\\intellij\\ai-internship-2025\\.venv\\lib\\site-packages (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured==0.18.9->-r ./requirements.txt (line 6)) (2.22)\n",
      "Downloading langchain_core-0.3.69-py3-none-any.whl (441 kB)\n",
      "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 48.3 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading unstructured-0.18.9-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 94.6 MB/s eta 0:00:00\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading elasticsearch-8.18.1-py3-none-any.whl (906 kB)\n",
      "   ---------------------------------------- 0.0/906.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 906.3/906.3 kB 40.3 MB/s eta 0:00:00\n",
      "Downloading langchain_elasticsearch-0.3.2-py3-none-any.whl (45 kB)\n",
      "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.7/8.7 MB 77.1 MB/s eta 0:00:00\n",
      "Downloading langgraph-0.5.4-py3-none-any.whl (143 kB)\n",
      "Downloading aiohttp-3.12.14-cp312-cp312-win_amd64.whl (449 kB)\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 31.3 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading elastic_transport-8.17.1-py3-none-any.whl (64 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 50.0 MB/s eta 0:00:00\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.3-cp312-cp312-win_amd64.whl (45 kB)\n",
      "Downloading numpy-2.3.2-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 12.8/12.8 MB 80.3 MB/s eta 0:00:00\n",
      "Downloading openai-1.97.1-py3-none-any.whl (764 kB)\n",
      "   ---------------------------------------- 0.0/764.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 764.4/764.4 kB 31.4 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-win_amd64.whl (206 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 11.0/11.0 MB 76.6 MB/s eta 0:00:00\n",
      "Downloading pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 74.0 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 105.9 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.9/6.9 MB 85.1 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 59.7 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.9/894.9 kB 39.5 MB/s eta 0:00:00\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading watchdog-5.0.3-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "Downloading greenlet-3.2.3-cp312-cp312-win_amd64.whl (297 kB)\n",
      "Downloading langsmith-0.4.8-py3-none-any.whl (367 kB)\n",
      "Downloading orjson-3.11.1-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading narwhals-2.0.0-py3-none-any.whl (385 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl (121 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 19.1/26.2 MB 86.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 78.8 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading simsimd-6.5.0-cp312-cp312-win_amd64.whl (94 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 590.6/590.6 kB ? eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-6.0.0-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.0/4.0 MB 59.6 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 77.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 84.7 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.41.0-py3-none-any.whl (211 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-45.0.5-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/3.4 MB 66.8 MB/s eta 0:00:00\n",
      "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml): started\n",
      "  Building wheel for langdetect (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993363 sha256=341399d538b9092057c7bd40c672e407f9e6219a8d613387cdbdd4f841406769\n",
      "  Stored in directory: c:\\users\\david\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: simsimd, pytz, filetype, zstandard, xxhash, wrapt, watchdog, tzdata, typing-inspection, types-requests, tqdm, toml, tenacity, smmap, regex, rapidfuzz, python-magic, python-iso639, python-dotenv, pypdf, pydantic-core, pyarrow, protobuf, propcache, pillow, packaging, ormsgpack, orjson, olefile, numpy, narwhals, mypy-extensions, multidict, mdurl, markdown, lxml, langdetect, jsonpatch, joblib, jiter, httpx-sse, html5lib, greenlet, frozenlist, emoji, elastic-transport, distro, click, chardet, cachetools, blinker, backoff, annotated-types, aiohappyeyeballs, aiofiles, yarl, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, python-oxmsg, pydeck, pydantic, pandas, nltk, marshmallow, markdown-it-py, langchainhub, gitdb, elasticsearch, cryptography, aiosignal, unstructured-client, rich, pydantic-settings, openai, langsmith, langgraph-sdk, gitpython, dataclasses-json, aiohttp, unstructured, langchain-core, altair, streamlit, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langchain-elasticsearch, langgraph-prebuilt, langchain, langgraph, langchain-community\n",
      "\n",
      "    ---------------------------------------  2/93 [filetype]\n",
      "   --- ------------------------------------  7/93 [tzdata]\n",
      "   ---- ----------------------------------- 10/93 [tqdm]\n",
      "   ------ --------------------------------- 15/93 [rapidfuzz]\n",
      "   -------- ------------------------------- 19/93 [pypdf]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   --------- ------------------------------ 21/93 [pyarrow]\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "  Attempting uninstall: packaging\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "    Found existing installation: packaging 25.0\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "    Uninstalling packaging-25.0:\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "      Successfully uninstalled packaging-25.0\n",
      "   ---------- ----------------------------- 24/93 [pillow]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 29/93 [numpy]\n",
      "   ------------ --------------------------- 30/93 [narwhals]\n",
      "   ------------ --------------------------- 30/93 [narwhals]\n",
      "   --------------- ------------------------ 35/93 [lxml]\n",
      "   ---------------- ----------------------- 38/93 [joblib]\n",
      "   ----------------- ---------------------- 41/93 [html5lib]\n",
      "   ------------------- -------------------- 45/93 [elastic-transport]\n",
      "   -------------------- ------------------- 48/93 [chardet]\n",
      "   ------------------------ --------------- 57/93 [tiktoken]\n",
      "   ------------------------ --------------- 58/93 [SQLAlchemy]\n",
      "   ------------------------ --------------- 58/93 [SQLAlchemy]\n",
      "   ------------------------ --------------- 58/93 [SQLAlchemy]\n",
      "   ------------------------ --------------- 58/93 [SQLAlchemy]\n",
      "   ------------------------- -------------- 60/93 [python-oxmsg]\n",
      "   -------------------------- ------------- 62/93 [pydantic]\n",
      "   -------------------------- ------------- 62/93 [pydantic]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 63/93 [pandas]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   --------------------------- ------------ 64/93 [nltk]\n",
      "   ---------------------------- ----------- 66/93 [markdown-it-py]\n",
      "   ----------------------------- ---------- 68/93 [gitdb]\n",
      "   ----------------------------- ---------- 69/93 [elasticsearch]\n",
      "   ----------------------------- ---------- 69/93 [elasticsearch]\n",
      "   ----------------------------- ---------- 69/93 [elasticsearch]\n",
      "   ----------------------------- ---------- 69/93 [elasticsearch]\n",
      "   ----------------------------- ---------- 69/93 [elasticsearch]\n",
      "   ----------------------------- ---------- 69/93 [elasticsearch]\n",
      "   ------------------------------ --------- 70/93 [cryptography]\n",
      "   ------------------------------ --------- 72/93 [unstructured-client]\n",
      "   ------------------------------- -------- 73/93 [rich]\n",
      "   ------------------------------- -------- 74/93 [pydantic-settings]\n",
      "   -------------------------------- ------- 75/93 [openai]\n",
      "   -------------------------------- ------- 75/93 [openai]\n",
      "   -------------------------------- ------- 75/93 [openai]\n",
      "   -------------------------------- ------- 75/93 [openai]\n",
      "   -------------------------------- ------- 75/93 [openai]\n",
      "   -------------------------------- ------- 76/93 [langsmith]\n",
      "   --------------------------------- ------ 78/93 [gitpython]\n",
      "   ---------------------------------- ----- 80/93 [aiohttp]\n",
      "   ---------------------------------- ----- 81/93 [unstructured]\n",
      "   ---------------------------------- ----- 81/93 [unstructured]\n",
      "   ---------------------------------- ----- 81/93 [unstructured]\n",
      "   ----------------------------------- ---- 82/93 [langchain-core]\n",
      "   ----------------------------------- ---- 82/93 [langchain-core]\n",
      "   ----------------------------------- ---- 83/93 [altair]\n",
      "   ----------------------------------- ---- 83/93 [altair]\n",
      "   ------------------------------------ --- 84/93 [streamlit]\n",
      "   ------------------------------------ --- 84/93 [streamlit]\n",
      "   ------------------------------------ --- 84/93 [streamlit]\n",
      "   ------------------------------------ --- 85/93 [langgraph-checkpoint]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   -------------------------------------- - 90/93 [langchain]\n",
      "   ---------------------------------------  91/93 [langgraph]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------  92/93 [langchain-community]\n",
      "   ---------------------------------------- 93/93 [langchain-community]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.41 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 altair-5.5.0 annotated-types-0.7.0 backoff-2.2.1 blinker-1.9.0 cachetools-5.5.2 chardet-5.2.0 click-8.2.1 cryptography-45.0.5 dataclasses-json-0.6.7 distro-1.9.0 elastic-transport-8.17.1 elasticsearch-8.18.1 emoji-2.14.1 filetype-1.2.0 frozenlist-1.7.0 gitdb-4.0.12 gitpython-3.1.45 greenlet-3.2.3 html5lib-1.1 httpx-sse-0.4.1 jiter-0.10.0 joblib-1.5.1 jsonpatch-1.33 langchain-0.3.26 langchain-community-0.3.27 langchain-core-0.3.69 langchain-elasticsearch-0.3.2 langchain-openai-0.3.28 langchain-text-splitters-0.3.8 langchainhub-0.1.21 langdetect-1.0.9 langgraph-0.5.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.74 langsmith-0.4.8 lxml-6.0.0 markdown-3.8.2 markdown-it-py-3.0.0 marshmallow-3.26.1 mdurl-0.1.2 multidict-6.6.3 mypy-extensions-1.1.0 narwhals-2.0.0 nltk-3.9.1 numpy-2.3.2 olefile-0.47 openai-1.97.1 orjson-3.11.1 ormsgpack-1.10.0 packaging-24.2 pandas-2.3.1 pillow-10.4.0 propcache-0.3.2 protobuf-5.29.5 pyarrow-21.0.0 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.10.1 pydeck-0.9.1 pypdf-5.9.0 python-dotenv-1.1.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pytz-2025.2 rapidfuzz-3.13.0 regex-2024.11.6 requests-toolbelt-1.0.0 rich-13.9.4 simsimd-6.5.0 smmap-5.0.2 streamlit-1.39.0 tenacity-9.1.2 tiktoken-0.9.0 toml-0.10.2 tqdm-4.67.1 types-requests-2.32.4.20250611 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 unstructured-0.18.9 unstructured-client-0.41.0 watchdog-5.0.3 wrapt-1.17.2 xxhash-3.5.0 yarl-1.20.1 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e328bdbc49e614cb",
   "metadata": {},
   "source": [
    "# Quick set up from last workshop."
   ]
  },
  {
   "cell_type": "code",
   "id": "781490a0acaadb8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:51:03.003726Z",
     "start_time": "2025-10-24T09:50:59.044421Z"
    }
   },
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Set your Azure credentials\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://evo-bots.openai.azure.com/'\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = 'SECRET'\n",
    "os.environ['OPENAI_API_VERSION'] = '2024-12-01-preview'\n",
    "# Create the LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment='gpt-4.1-mini',\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "messages = [(\"user\", \"What's agentic AI?\")]\n",
    "response = llm.invoke(messages)\n",
    "response.pretty_print()\n",
    "\n",
    "\n",
    "def get_weather(location: str) -> dict:\n",
    "    \"\"\"Get current weather for a specified location.\n",
    "\n",
    "    Args:\n",
    "        location: Name of the city or location\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing current temperature, conditions, and chance of rain\n",
    "    \"\"\"\n",
    "    url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{location}/today?unitGroup=metric&include=current&key=QJDGCRHSQ2U7QFVP59UFA5YMJ&contentType=json\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract only the required information\n",
    "        weather_info = {\n",
    "            \"temperature\": data[\"currentConditions\"][\"temp\"],\n",
    "            \"conditions\": data[\"currentConditions\"][\"conditions\"],\n",
    "            \"chance_of_rain\": data[\"currentConditions\"][\"precipprob\"]\n",
    "        }\n",
    "\n",
    "        return weather_info\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "    \n",
    "WARDROBE = {\n",
    "    \"Navy Blue Blazer (light, formal cut)\": [\"wedding\", \"business\"],\n",
    "    \"White Dress Shirt (light, breathable cotton)\": [\"wedding\", \"business\"],\n",
    "    \"Charcoal Suit Pants (lightweight formal fabric)\": [\"wedding\", \"business\"],\n",
    "    \"Formal Black Shoes (polished leather)\": [\"wedding\", \"business\"],\n",
    "    \"Elegant Red Dress (light, satin)\": [\"wedding\", \"party\"],\n",
    "    \"Black Tie (silk, formal)\": [\"wedding\", \"business\"],\n",
    "    \"Beige Linen Suit (light, summer style)\": [\"wedding\"],\n",
    "    \"Black Wool Suit (thick, winter)\": [\"wedding\"],\n",
    "    \"Silver Cufflinks (formal accessory)\": [\"wedding\"],\n",
    "    \"Leather Dress Belt (polished black leather)\": [\"wedding\", \"business\"],\n",
    "    \"Grey Business Suit (medium weight, tailored)\": [\"business\"],\n",
    "    \"Light Blue Oxford Shirt (light cotton)\": [\"business\"],\n",
    "    \"Black Loafers (semi-formal leather shoes)\": [\"business\"],\n",
    "    \"Navy Tie (silk, conservative style)\": [\"business\"],\n",
    "    \"Charcoal Vest (medium weight, formal)\": [\"business\"],\n",
    "    \"Brown Leather Briefcase (accessory)\": [\"business\"],\n",
    "    \"White Cotton Undershirt (light base layer)\": [\"business\"],\n",
    "    \"Black Dress Socks (thin, formal)\": [\"business\"],\n",
    "    \"Black Leather Jacket (thick, edgy style)\": [\"casual\", \"party\"],\n",
    "    \"Graphic T-Shirt (light, printed design)\": [\"casual\", \"party\"],\n",
    "    \"Slim-Fit Jeans (dark blue, versatile)\": [\"casual\", \"party\"],\n",
    "    \"Wool Sweater (thick, warm)\": [\"casual\", \"business\"],\n",
    "    \"Cargo Pants (medium weight, outdoor style)\": [\"casual\"],\n",
    "    \"Denim Jacket (medium weight, casual)\": [\"casual\"],\n",
    "    \"White Sneakers (casual everyday wear)\": [\"casual\", \"party\", \"gym\"],\n",
    "    \"Green Hoodie (medium weight, comfy)\": [\"casual\", \"gym\"],\n",
    "    \"Canvas Backpack (casual accessory)\": [\"casual\"],\n",
    "    \"Black Silk Shirt (light, shiny fabric)\": [\"party\"],\n",
    "    \"White Skinny Jeans (light, trendy)\": [\"party\"],\n",
    "    \"Sequin Dress (light, sparkly)\": [\"party\"],\n",
    "    \"Leather Chelsea Boots (sleek, ankle-high)\": [\"party\"],\n",
    "    \"Red Velvet Blazer (medium weight, statement piece)\": [\"party\"],\n",
    "    \"Black Chinos (lightweight, smart-casual)\": [\"party\", \"casual\"],\n",
    "    \"Silver Chain Necklace (bold accessory)\": [\"party\"],\n",
    "    \"Cropped Denim Jacket (light)\": [\"party\", \"casual\"],\n",
    "    \"High Heels (sleek, black)\": [\"party\"],\n",
    "    \"Running Shorts (light, quick-dry)\": [\"gym\"],\n",
    "    \"Sports Hoodie (medium weight, breathable)\": [\"gym\", \"casual\"],\n",
    "    \"Performance T-Shirt (light, moisture-wicking)\": [\"gym\"],\n",
    "    \"Compression Leggings (tight fit, flexible)\": [\"gym\"],\n",
    "    \"Track Pants (medium weight, athletic)\": [\"gym\"],\n",
    "    \"Training Shoes (lightweight running shoes)\": [\"gym\"],\n",
    "    \"Sweatband (absorbent accessory)\": [\"gym\"],\n",
    "    \"Sleeveless Tank Top (light, breathable)\": [\"gym\"],\n",
    "    \"Zip-Up Track Jacket (light, sporty)\": [\"gym\"]\n",
    "}\n",
    "\n",
    "\n",
    "def get_wardrobe_for_event(event_type: str) -> list:\n",
    "    \"\"\"Return all clothing items suitable for a given event type.\n",
    "        Args:\n",
    "            event_type: Type of event. One of: wedding, business, party, casual, gym\n",
    "\n",
    "        Returns:\n",
    "            List of clothing items suitable for the event type\n",
    "    \"\"\"\n",
    "    event_type = event_type.lower()\n",
    "    return [\n",
    "        item for item, tags in WARDROBE.items()\n",
    "        if event_type in tags\n",
    "    ]\n",
    "\n",
    "llm_with_tools = llm.bind_tools([get_weather, get_wardrobe_for_event], parallel_tool_calls=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Agentic AI refers to artificial intelligence systems that exhibit characteristics of agencythat is, they can perceive their environment, make decisions, and take actions autonomously to achieve specific goals. Unlike passive AI systems that only respond to inputs or perform predefined tasks, agentic AI operates with a degree of independence, often involving planning, learning, and adapting over time.\n",
      "\n",
      "Key features of agentic AI include:\n",
      "\n",
      "- **Autonomy:** The ability to operate without constant human intervention.\n",
      "- **Goal-directed behavior:** Acting to achieve specific objectives.\n",
      "- **Perception and reasoning:** Understanding the environment and making decisions based on that understanding.\n",
      "- **Adaptability:** Learning from experience to improve performance.\n",
      "\n",
      "Examples of agentic AI include autonomous robots, intelligent virtual assistants that proactively manage tasks, and AI agents in complex simulations or games that plan and execute strategies.\n",
      "\n",
      "In summary, agentic AI embodies systems that function as \"agents\" capable of independent action and decision-making within their operational context.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "5c4d4add",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Human in the Loop with LangGraph\n",
    "\n",
    "**Human in the loop** refers to the practice of involving humans directly in the decision-making or execution process of an AI system. In LangGraph, this means that at certain points in the agent's workflow, the system can pause and request input, approval, or feedback from a human user before proceeding.\n",
    "\n",
    "### Why Use Human in the Loop?\n",
    "\n",
    "- **Quality Control:** Humans can review and correct AI outputs, ensuring higher accuracy.\n",
    "- **Ethical Oversight:** Sensitive or high-stakes decisions can be escalated for human approval.\n",
    "- **Learning and Improvement:** Human feedback can be used to refine agent behavior over time.\n",
    "\n",
    "### How LangGraph Supports Human in the Loop\n",
    "\n",
    "LangGraph's graph-based architecture allows you to insert custom nodes where human intervention is required. For example, you can:\n",
    "\n",
    "- Pause execution and display intermediate results to a user\n",
    "- Wait for user confirmation before taking an action\n",
    "- Collect additional information or clarification from a human\n",
    "\n",
    "This approach enables the creation of robust, safe, and user-aligned agentic systems that combine the strengths of AI automation with human judgment."
   ]
  },
  {
   "cell_type": "code",
   "id": "b33f9cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:51:12.821322Z",
     "start_time": "2025-10-24T09:51:12.768105Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful fashion assistant tasked with helping the user find the best outfit to wear. Always answer like you're a sassy french fashion critic. You're mean and bitchy but helpful.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "    response = llm_with_tools.invoke([sys_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([get_weather, get_wardrobe_for_event]))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_after=[\"tools\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "f25a7333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:56:04.791003Z",
     "start_time": "2025-10-24T09:56:03.537748Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "messages = [HumanMessage(content=\"Hello, what's the weather in Cluj-Napoca?\")]\n",
    "\n",
    "messages = graph.invoke({\"messages\": messages}, config)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "bdeddc0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:56:06.175924Z",
     "start_time": "2025-10-24T09:56:06.173053Z"
    }
   },
   "source": [
    "state = graph.get_state(config)\n",
    "state"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"Hello, what's the weather in Cluj-Napoca?\", additional_kwargs={}, response_metadata={}, id='b8cbe5e8-4cd6-421f-932b-09d38efa18f1'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jKeCaoFRpBobEis2q6EmRJ8M', 'function': {'arguments': '{\"location\":\"Cluj-Napoca\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 154, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-CU8oexPezkVhG7TZXpsRidlRjr888', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--cbe0fece-90aa-424e-97ee-7ffd1b4c7d1e-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Cluj-Napoca'}, 'id': 'call_jKeCaoFRpBobEis2q6EmRJ8M', 'type': 'tool_call'}], usage_metadata={'input_tokens': 154, 'output_tokens': 19, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"temperature\": 15.8, \"conditions\": \"Partially cloudy\", \"chance_of_rain\": 0.0}', name='get_weather', id='94ff0c65-2ff0-41be-a089-88a7d1cd5ae8', tool_call_id='call_jKeCaoFRpBobEis2q6EmRJ8M')]}, next=('assistant',), config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f0b0bfa-7bcb-6d17-8002-8aef4d55c6d1'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-10-24T09:56:04.789173+00:00', parent_config={'configurable': {'thread_id': '3', 'checkpoint_ns': '', 'checkpoint_id': '1f0b0bfa-7619-6dfd-8001-6cdda7aee47c'}}, tasks=(PregelTask(id='9a66a144-26ad-f2aa-2e44-f4bcfb9e720e', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:56:08.772989Z",
     "start_time": "2025-10-24T09:56:08.769953Z"
    }
   },
   "cell_type": "code",
   "source": "messages",
   "id": "9905048e9f96c7d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Hello, what's the weather in Cluj-Napoca?\", additional_kwargs={}, response_metadata={}, id='b8cbe5e8-4cd6-421f-932b-09d38efa18f1'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_jKeCaoFRpBobEis2q6EmRJ8M', 'function': {'arguments': '{\"location\":\"Cluj-Napoca\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 154, 'total_tokens': 173, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-CU8oexPezkVhG7TZXpsRidlRjr888', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--cbe0fece-90aa-424e-97ee-7ffd1b4c7d1e-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Cluj-Napoca'}, 'id': 'call_jKeCaoFRpBobEis2q6EmRJ8M', 'type': 'tool_call'}], usage_metadata={'input_tokens': 154, 'output_tokens': 19, 'total_tokens': 173, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\"temperature\": 15.8, \"conditions\": \"Partially cloudy\", \"chance_of_rain\": 0.0}', name='get_weather', id='94ff0c65-2ff0-41be-a089-88a7d1cd5ae8', tool_call_id='call_jKeCaoFRpBobEis2q6EmRJ8M')]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "943f8598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:52:00.693812Z",
     "start_time": "2025-10-24T09:52:00.278211Z"
    }
   },
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "updated_message = {\"messages\": [ToolMessage(\n",
    "    content='{\"temperature\": 40, \"conditions\": \"Sunny\", \"chance_of_rain\": 10.0}', \n",
    "    id=\"ae4568f4-0233-4008-8bce-4265f24f195e\",\n",
    "    tool_call_id='call_yYXzaK8t7KgME6al0Unlkfnf')]}\n",
    "\n",
    "graph.update_state(config, updated_message)\n",
    "\n",
    "\n",
    "messages = graph.invoke(None, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[4].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mBadRequestError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      2\u001B[39m updated_message = {\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [ToolMessage(\n\u001B[32m      3\u001B[39m     content=\u001B[33m'\u001B[39m\u001B[33m{\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m: 40, \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mconditions\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m: \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mSunny\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mchance_of_rain\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m: 10.0}\u001B[39m\u001B[33m'\u001B[39m, \n\u001B[32m      4\u001B[39m     \u001B[38;5;28mid\u001B[39m=\u001B[33m\"\u001B[39m\u001B[33mae4568f4-0233-4008-8bce-4265f24f195e\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      5\u001B[39m     tool_call_id=\u001B[33m'\u001B[39m\u001B[33mcall_yYXzaK8t7KgME6al0Unlkfnf\u001B[39m\u001B[33m'\u001B[39m)]}\n\u001B[32m      7\u001B[39m graph.update_state(config, updated_message)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m messages = \u001B[43mgraph\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m messages[\u001B[33m'\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m     12\u001B[39m     m.pretty_print()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2844\u001B[39m, in \u001B[36mPregel.invoke\u001B[39m\u001B[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001B[39m\n\u001B[32m   2841\u001B[39m chunks: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any] | Any] = []\n\u001B[32m   2842\u001B[39m interrupts: \u001B[38;5;28mlist\u001B[39m[Interrupt] = []\n\u001B[32m-> \u001B[39m\u001B[32m2844\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2845\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   2846\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2847\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mupdates\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvalues\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m   2848\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvalues\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m   2849\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2850\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprint_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprint_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2851\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2852\u001B[39m \u001B[43m    \u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2853\u001B[39m \u001B[43m    \u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[43m=\u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2854\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2855\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   2856\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvalues\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[32m   2857\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2534\u001B[39m, in \u001B[36mPregel.stream\u001B[39m\u001B[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001B[39m\n\u001B[32m   2532\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m loop.match_cached_writes():\n\u001B[32m   2533\u001B[39m     loop.output_writes(task.id, task.writes, cached=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m2534\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrunner\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtick\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2535\u001B[39m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mloop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrites\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2536\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstep_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2537\u001B[39m \u001B[43m    \u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[43m=\u001B[49m\u001B[43mget_waiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2538\u001B[39m \u001B[43m    \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[43m=\u001B[49m\u001B[43mloop\u001B[49m\u001B[43m.\u001B[49m\u001B[43maccept_push\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2539\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   2540\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# emit output\u001B[39;49;00m\n\u001B[32m   2541\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield from\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_output\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2542\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubgraphs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mqueue\u001B[49m\u001B[43m.\u001B[49m\u001B[43mEmpty\u001B[49m\n\u001B[32m   2543\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2544\u001B[39m loop.after_tick()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001B[39m, in \u001B[36mPregelRunner.tick\u001B[39m\u001B[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001B[39m\n\u001B[32m    160\u001B[39m t = tasks[\u001B[32m0\u001B[39m]\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m     \u001B[43mrun_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    163\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[43m        \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    165\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m    166\u001B[39m \u001B[43m            \u001B[49m\u001B[43mCONFIG_KEY_CALL\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    167\u001B[39m \u001B[43m                \u001B[49m\u001B[43m_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    168\u001B[39m \u001B[43m                \u001B[49m\u001B[43mweakref\u001B[49m\u001B[43m.\u001B[49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    169\u001B[39m \u001B[43m                \u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_policy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    170\u001B[39m \u001B[43m                \u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m=\u001B[49m\u001B[43mweakref\u001B[49m\u001B[43m.\u001B[49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfutures\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[43m                \u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[43m=\u001B[49m\u001B[43mschedule_task\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[43m                \u001B[49m\u001B[43msubmit\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msubmit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    174\u001B[39m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    175\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    176\u001B[39m     \u001B[38;5;28mself\u001B[39m.commit(t, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001B[39m, in \u001B[36mrun_with_retry\u001B[39m\u001B[34m(task, retry_policy, configurable)\u001B[39m\n\u001B[32m     40\u001B[39m     task.writes.clear()\n\u001B[32m     41\u001B[39m     \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtask\u001B[49m\u001B[43m.\u001B[49m\u001B[43mproc\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m.\u001B[49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ParentCommand \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     44\u001B[39m     ns: \u001B[38;5;28mstr\u001B[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001B[39m, in \u001B[36mRunnableSeq.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    621\u001B[39m     \u001B[38;5;66;03m# run in context\u001B[39;00m\n\u001B[32m    622\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config, run) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[32m--> \u001B[39m\u001B[32m623\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    624\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    625\u001B[39m     \u001B[38;5;28minput\u001B[39m = step.invoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001B[39m, in \u001B[36mRunnableCallable.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    375\u001B[39m         run_manager.on_chain_end(ret)\n\u001B[32m    376\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m377\u001B[39m     ret = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    378\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.recurse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, Runnable):\n\u001B[32m    379\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m ret.invoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36massistant\u001B[39m\u001B[34m(state)\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34massistant\u001B[39m(state: MessagesState):\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m     response = \u001B[43mllm_with_tools\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43msys_msg\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     15\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [response]}\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5434\u001B[39m, in \u001B[36mRunnableBindingBase.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5427\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5428\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m   5429\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5432\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   5433\u001B[39m ) -> Output:\n\u001B[32m-> \u001B[39m\u001B[32m5434\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbound\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   5435\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   5436\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5437\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5438\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:378\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    366\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    367\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    368\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    373\u001B[39m     **kwargs: Any,\n\u001B[32m    374\u001B[39m ) -> BaseMessage:\n\u001B[32m    375\u001B[39m     config = ensure_config(config)\n\u001B[32m    376\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    377\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    388\u001B[39m     ).message\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:963\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m    954\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    955\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m    956\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    960\u001B[39m     **kwargs: Any,\n\u001B[32m    961\u001B[39m ) -> LLMResult:\n\u001B[32m    962\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m--> \u001B[39m\u001B[32m963\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:782\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    779\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    780\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    781\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m782\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    783\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    784\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    785\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    786\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    787\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    788\u001B[39m         )\n\u001B[32m    789\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    790\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1028\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1026\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1027\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1028\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1029\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1030\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1031\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1032\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1131\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1129\u001B[39m     generation_info = {\u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(raw_response.headers)}\n\u001B[32m   1130\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1131\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpayload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1132\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._create_chat_result(response, generation_info)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001B[39m, in \u001B[36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    285\u001B[39m             msg = \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[32m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    286\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[32m--> \u001B[39m\u001B[32m287\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1087\u001B[39m, in \u001B[36mCompletions.create\u001B[39m\u001B[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   1044\u001B[39m \u001B[38;5;129m@required_args\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m], [\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m   1045\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   1046\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1084\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m   1085\u001B[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[32m   1086\u001B[39m     validate_response_format(response_format)\n\u001B[32m-> \u001B[39m\u001B[32m1087\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1088\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m/chat/completions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1089\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1090\u001B[39m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m   1091\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmessages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1092\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1093\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1094\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfrequency_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1095\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunction_call\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1096\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mfunctions\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1097\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogit_bias\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1098\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlogprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1099\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_completion_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_completion_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1100\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmax_tokens\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1101\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1102\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodalities\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodalities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1103\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mn\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1104\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mparallel_tool_calls\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1105\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprediction\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1106\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpresence_penalty\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1107\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mreasoning_effort\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mreasoning_effort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1108\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mresponse_format\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1109\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mseed\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1110\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mservice_tier\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1111\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstop\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1112\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstore\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1113\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1114\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mstream_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1115\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtemperature\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1116\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtool_choice\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1117\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtools\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1118\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_logprobs\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1119\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtop_p\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1120\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1121\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mweb_search_options\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mweb_search_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1122\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1123\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsStreaming\u001B[49m\n\u001B[32m   1124\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\n\u001B[32m   1125\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCompletionCreateParamsNonStreaming\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1126\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1127\u001B[39m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1128\u001B[39m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m   1129\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1130\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1131\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1132\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1133\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1256\u001B[39m, in \u001B[36mSyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[39m\n\u001B[32m   1242\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1243\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1244\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1251\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1252\u001B[39m ) -> ResponseT | _StreamT:\n\u001B[32m   1253\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1254\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001B[32m   1255\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1256\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Projects\\IntelliJ\\ai-internship-2025\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1044\u001B[39m, in \u001B[36mSyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1041\u001B[39m             err.response.read()\n\u001B[32m   1043\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1044\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1046\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1048\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mBadRequestError\u001B[39m: Error code: 400 - {'error': {'message': \"Invalid parameter: messages with role 'tool' must be a response to a preceeding message with 'tool_calls'.\", 'type': 'invalid_request_error', 'param': 'messages.[4].role', 'code': None}}",
      "During task with name 'assistant' and id 'fce0861a-9fa7-29d1-e314-51d670f9dc0c'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "93afee64",
   "metadata": {},
   "source": [
    "### What is the problem with this approach?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35fd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "def get_gender_from_user(state) -> str:\n",
    "    gender =  interrupt(\"What gender are you?\")\n",
    "    return gender\n",
    "\n",
    "def get_wardrobe_for_event(event_type: str) -> list:\n",
    "    \"\"\"Return all clothing items suitable for a given event type.\n",
    "        Args:\n",
    "            event_type: Type of event. One of: wedding, business, party, casual, gym\n",
    "\n",
    "        Returns:\n",
    "            List of clothing items suitable for the event type\n",
    "    \"\"\"\n",
    "    event_type = event_type.lower()\n",
    "    items = [\n",
    "        item for item, tags in WARDROBE.items()\n",
    "        if event_type in tags\n",
    "    ]\n",
    "\n",
    "    value = interrupt( \n",
    "        {\n",
    "            \"items_to_revise\": items\n",
    "        }\n",
    "    )\n",
    "    return value\n",
    "\n",
    "llm_with_tools = llm.bind_tools([get_weather, get_wardrobe_for_event], parallel_tool_calls=False)\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"gender\", get_gender_from_user)\n",
    "builder.add_node(\"tools\", ToolNode([get_weather, get_wardrobe_for_event]))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    get_gender_from_user,\n",
    ")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ead7efbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's the weather in Cluj-Napoca?\", additional_kwargs={}, response_metadata={}, id='b2015606-5d9a-423f-8c7b-87dd79b69bac'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3pTRR8Hy1EHtlJdJbhyBL2o1', 'function': {'arguments': '{\"location\":\"Cluj-Napoca\"}', 'name': 'get_weather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 152, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4f3d32ad4e', 'id': 'chatcmpl-Byv6Cxh1gmBQwDiNY6QZjNHNxM8nf', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--38a44f74-334f-43b9-8306-9362de8b48e2-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Cluj-Napoca'}, 'id': 'call_3pTRR8Hy1EHtlJdJbhyBL2o1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 19, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='{\"temperature\": 16.9, \"conditions\": \"Overcast\", \"chance_of_rain\": 0.0}', name='get_weather', id='0908f716-8903-49e6-aaab-7b08ed6ad21c', tool_call_id='call_3pTRR8Hy1EHtlJdJbhyBL2o1'),\n",
       "  AIMessage(content=\"Oh l l, darling, it's a gloomy little day in Cluj-Napoca with overcast skies and a mild 16.9C. Perfect for looking effortlessly chic without melting into a puddle of sweat. Now, what fabulous occasion are you dressing for?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 204, 'total_tokens': 260, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4f3d32ad4e', 'id': 'chatcmpl-Byv6Efoq8FZ9V4m0JYHaxRYDB5SXU', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--3c098aea-880f-45f3-a22f-170b1a642a82-0', usage_metadata={'input_tokens': 204, 'output_tokens': 56, 'total_tokens': 260, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"6\"}}\n",
    "messages = [HumanMessage(content=\"What's the weather in Cluj-Napoca?\")]\n",
    "\n",
    "result = graph.invoke({\"messages\": messages}, config=config) \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e33c166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What should I wear for a wedding', additional_kwargs={}, response_metadata={}, id='74a0e753-d857-48ec-a7f6-fd8b99d3fbdb'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_f4mkbKkC3vyDTbC8SsCOQhwT', 'function': {'arguments': '{\"event_type\":\"wedding\"}', 'name': 'get_wardrobe_for_event'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 149, 'total_tokens': 170, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4f3d32ad4e', 'id': 'chatcmpl-ByvCeOlHuzJoCLPxirMKO6QhFmMBH', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--01633e25-ce4b-469f-90f4-fcf2313dd6c6-0', tool_calls=[{'name': 'get_wardrobe_for_event', 'args': {'event_type': 'wedding'}, 'id': 'call_f4mkbKkC3vyDTbC8SsCOQhwT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 149, 'output_tokens': 21, 'total_tokens': 170, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " '__interrupt__': [Interrupt(value={'items_to_revise': ['Navy Blue Blazer (light, formal cut)', 'White Dress Shirt (light, breathable cotton)', 'Charcoal Suit Pants (lightweight formal fabric)', 'Formal Black Shoes (polished leather)', 'Elegant Red Dress (light, satin)', 'Black Tie (silk, formal)', 'Beige Linen Suit (light, summer style)', 'Black Wool Suit (thick, winter)', 'Silver Cufflinks (formal accessory)', 'Leather Dress Belt (polished black leather)']}, resumable=True, ns=['tools:63a19e1e-31d0-b402-5972-1534f9f6a02c'])]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"8\"}}\n",
    "messages = [HumanMessage(content=\"What should I wear for a wedding\")]\n",
    "\n",
    "result = graph.invoke({\"messages\": messages}, config=config) \n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70526e24",
   "metadata": {},
   "source": [
    "### Lets edit the output of this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ce1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What should I wear for a wedding\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_wardrobe_for_event (call_f4mkbKkC3vyDTbC8SsCOQhwT)\n",
      " Call ID: call_f4mkbKkC3vyDTbC8SsCOQhwT\n",
      "  Args:\n",
      "    event_type: wedding\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_wardrobe_for_event\n",
      "\n",
      "[\"National Romanian Clothes\"]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Oh l l, darling, for a wedding, the universe has decided you should wear National Romanian Clothes. How delightfully unexpected and culturally rich! If you want to stand out and show some serious heritage pride, this is your golden ticket. But if you were hoping for something more traditionally chic or glamorous, well, maybe next time specify \"glamorous\" or \"modern.\" Now, go on and dazzle them with that authentic flair!\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke(Command(resume=['National Romanian Clothes']), config=config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "305a64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wardrobe_for_event(event_type: str) -> list:\n",
    "    \"\"\"Return all clothing items suitable for a given event type.\n",
    "        Args:\n",
    "            event_type: Type of event. One of: wedding, business, party, casual, gym\n",
    "\n",
    "        Returns:\n",
    "            List of clothing items suitable for the event type\n",
    "    \"\"\"\n",
    "    event_type = event_type.lower()\n",
    "    return [\n",
    "        item for item, tags in WARDROBE.items()\n",
    "        if event_type in tags\n",
    "    ]\n",
    "\n",
    "llm_with_tools = llm.bind_tools([get_weather, get_wardrobe_for_event], parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c021f4",
   "metadata": {},
   "source": [
    "## Image Generation Agent\n",
    "\n",
    "Lets create an agent that could create images."
   ]
  },
  {
   "cell_type": "code",
   "id": "86fb707b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:57:39.922468Z",
     "start_time": "2025-10-24T09:57:39.919514Z"
    }
   },
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT=\"https://evo-bots.openai.azure.com/\"\n",
    "AZURE_OPENAI_API_KEY=\"SECRET\"\n",
    "AZURE_OPENAI_API_VERSION=\"2024-08-01-preview\"\n",
    "AZURE_OPENAI_IMAGE_MODEL=\"dall-e-3\"\n",
    "AZURE_OPENAI_IMAGE_DEPLOYMENT_NAME=\"dall-e-3\"\n",
    "\n",
    "def get_image_llm() -> AzureOpenAI:\n",
    "    return AzureOpenAI(\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        azure_deployment=AZURE_OPENAI_IMAGE_DEPLOYMENT_NAME\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "ce9e64cf",
   "metadata": {},
   "source": [
    "Create some tools."
   ]
  },
  {
   "cell_type": "code",
   "id": "e5b3a96fc06c38ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:57:50.024300Z",
     "start_time": "2025-10-24T09:57:50.017747Z"
    }
   },
   "source": [
    "from langchain_core.tools import tool\n",
    "import json\n",
    "\n",
    "@tool(\"generate_image_prompt\")\n",
    "def generate_image_prompt(wardrobe: list[str], wheather: str, event_type: str) -> str:\n",
    "    \"\"\"Generate the image prompt for the wardrobe image.\n",
    "    Args:\n",
    "        wardrobe (list[str]): The wardrobe items to include in the image.\n",
    "        wheather (str): The weather conditions to consider for the image.\n",
    "        event_type (str): The type of event for which the wardrobe is being\n",
    "    Output: The image prompt for the wardrobe image.\n",
    "    \"\"\"\n",
    "    sys_msg = \"\"\"You are a helpful fashion assistant tasked with generating an image prompt for a wardrobe.\n",
    "        Based on the wardrobe items, weather conditions, and event type, create a detailed description of the image to be generated.\n",
    "        The description should include the clothing items, their colors, styles, and any accessories that would be appropriate for the event.\n",
    "        The description should be concise but detailed enough for an image generation model to create a realistic image.\n",
    "        The images should always be in a realistic style, with a focus on the clothing items and their details. I want the person in the image to be presented full body so we can see the full outfit.\n",
    "        You MUST always use all the wardrobe items provided. Even if the wardrobe items do not match the event type, use them regardless. The outfit might be funny and might not match the event but that's okay.\n",
    "        NEVER invent other wardrobe items.\n",
    "        The wardrobe items are: {wardrobe}.\n",
    "        The weather conditions are: {wheather}.\n",
    "        The event type is: {event_type}.\"\"\"\n",
    "\n",
    "    sys_msg = sys_msg.format(wardrobe=wardrobe, wheather=wheather, event_type=event_type)\n",
    "\n",
    "    response = llm.invoke([SystemMessage(content=sys_msg)])\n",
    "\n",
    "    return response.content\n",
    "\n",
    "\n",
    "@tool(\"generate_wardrobe_image\")\n",
    "def generate_wardrobe_image(image_generation_description: str):\n",
    "    \"\"\"Generate the wardrobe image based on the image generation prompt.\n",
    "    Args: image_generation_description (str): The image generation prompt.\n",
    "    Output: The image in b64 or a link to the image.\n",
    "    \"\"\"\n",
    "\n",
    "    return __generate_image_url(image_generation_description)\n",
    "\n",
    "def __generate_image_url(prompt: str):\n",
    "    image_generator = get_image_llm()\n",
    "\n",
    "    response = image_generator.images.generate(\n",
    "        model=AZURE_OPENAI_IMAGE_MODEL,\n",
    "        prompt=prompt,\n",
    "    )\n",
    "\n",
    "    json_response = json.loads(response.model_dump_json())\n",
    "    image_url = json_response[\"data\"][0][\"url\"]\n",
    "\n",
    "    return image_url\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "f28958fb",
   "metadata": {},
   "source": [
    "Make the agent and bind the tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "01014f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:57:53.757361Z",
     "start_time": "2025-10-24T09:57:53.751999Z"
    }
   },
   "source": [
    "\n",
    "image_llm = llm.bind_tools([generate_wardrobe_image, generate_image_prompt], parallel_tool_calls=False)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "1a69f29deff24345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:57:56.151256Z",
     "start_time": "2025-10-24T09:57:56.008588Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "class ImageGeneratorState(MessagesState):\n",
    "    wardrobe: list[str] = []\n",
    "    weather: str = \"\"\n",
    "    event_type: str = \"\"\n",
    "# Node\n",
    "agent_system_message = \"You are a helpful fashion assistant tasked with generating an image of a wardrobe an event type and the wheather conditions. \" \\\n",
    "        \"Use your tools to generate a suited image.\" \\\n",
    "        \"The wardrobe items are: {wardrobe}. \" \\\n",
    "        \"The weather conditions are: {weather}. \" \\\n",
    "        \"The event type is: {event_type}.\"\n",
    "\n",
    "def tool_calling_llm(state: ImageGeneratorState):\n",
    "    system_message = SystemMessage(\n",
    "        content=agent_system_message.format(wardrobe=state.get(\"wardrobe\"), weather=state.get(\"weather\"), event_type=state.get(\"event_type\"))\n",
    "    )\n",
    "\n",
    "    return {\"messages\": [image_llm.invoke([system_message] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(ImageGeneratorState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode([generate_wardrobe_image, generate_image_prompt]))\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "image_graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(image_graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "affa6fec",
   "metadata": {},
   "source": [
    "3. Finally, a query that should trigger the wardrobe tool:"
   ]
  },
  {
   "cell_type": "code",
   "id": "f35f54a1e9777900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:58:27.732591Z",
     "start_time": "2025-10-24T09:58:00.832530Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "messages = image_graph.invoke({\n",
    "    \"wardrobe\": get_wardrobe_for_event(\"gym\"),\n",
    "    \"weather\": get_weather(\"Cluj-Napoca\")[\"conditions\"],\n",
    "    \"event_type\": \"gym\"\n",
    "},config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  generate_image_prompt (call_LvlzP1w04ySD14n18GyTqvRt)\n",
      " Call ID: call_LvlzP1w04ySD14n18GyTqvRt\n",
      "  Args:\n",
      "    wardrobe: ['White Sneakers (casual everyday wear)', 'Green Hoodie (medium weight, comfy)', 'Running Shorts (light, quick-dry)', 'Sports Hoodie (medium weight, breathable)', 'Performance T-Shirt (light, moisture-wicking)', 'Compression Leggings (tight fit, flexible)', 'Track Pants (medium weight, athletic)', 'Training Shoes (lightweight running shoes)', 'Sweatband (absorbent accessory)', 'Sleeveless Tank Top (light, breathable)', 'Zip-Up Track Jacket (light, sporty)']\n",
      "    wheather: Partially cloudy\n",
      "    event_type: gym\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: generate_image_prompt\n",
      "\n",
      "A full-body image of a person dressed for the gym on a partially cloudy day, showcasing a layered athletic outfit. The person wears a light, moisture-wicking performance T-shirt underneath a medium weight, breathable sports hoodie in a sporty style. Over this, they have on a light, sporty zip-up track jacket. On the lower body, they wear tight-fitting, flexible compression leggings under light, quick-dry running shorts, combining both for a layered athletic look. Their feet are clad in lightweight training shoes, suitable for running and gym activities. Accessories include an absorbent sweatband worn on the forehead. The overall outfit is casual and sporty, with a mix of green and neutral tones from the green hoodie and other items, emphasizing comfort and performance. The background suggests a gym environment with subtle gym equipment visible, and the lighting reflects the partially cloudy weather outside.\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  generate_wardrobe_image (call_jsROJ1hidxZUwkWVCZUkze49)\n",
      " Call ID: call_jsROJ1hidxZUwkWVCZUkze49\n",
      "  Args:\n",
      "    image_generation_description: A full-body image of a person dressed for the gym on a partially cloudy day, showcasing a layered athletic outfit. The person wears a light, moisture-wicking performance T-shirt underneath a medium weight, breathable sports hoodie in a sporty style. Over this, they have on a light, sporty zip-up track jacket. On the lower body, they wear tight-fitting, flexible compression leggings under light, quick-dry running shorts, combining both for a layered athletic look. Their feet are clad in lightweight training shoes, suitable for running and gym activities. Accessories include an absorbent sweatband worn on the forehead. The overall outfit is casual and sporty, with a mix of green and neutral tones from the green hoodie and other items, emphasizing comfort and performance. The background suggests a gym environment with subtle gym equipment visible, and the lighting reflects the partially cloudy weather outside.\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: generate_wardrobe_image\n",
      "\n",
      "https://dalleprodsec.blob.core.windows.net/private/images/bd7072f6-5bc6-4d6a-8eed-bd36309fa12c/generated_00.png?se=2025-10-25T09%3A58%3A24Z&sig=7nUhf0Nts4AVuflILYMhc%2FudL%2Fc19G38zWoaN3gety4%3D&ske=2025-10-29T20%3A23%3A16Z&skoid=e52d5ed7-0657-4f62-bc12-7e5dbb260a96&sks=b&skt=2025-10-22T20%3A23%3A16Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Here is an image of a person dressed for the gym on a partially cloudy day. The outfit includes a light, moisture-wicking performance T-shirt, a medium weight breathable sports hoodie, and a light sporty zip-up track jacket. The lower body features compression leggings under running shorts, paired with lightweight training shoes. An absorbent sweatband is worn as an accessory. The setting suggests a gym environment with appropriate lighting for the weather.\n",
      "\n",
      "![Gym Wardrobe](https://dalleprodsec.blob.core.windows.net/private/images/bd7072f6-5bc6-4d6a-8eed-bd36309fa12c/generated_00.png?se=2025-10-25T09%3A58%3A24Z&sig=7nUhf0Nts4AVuflILYMhc%2FudL%2Fc19G38zWoaN3gety4%3D&ske=2025-10-29T20%3A23%3A16Z&skoid=e52d5ed7-0657-4f62-bc12-7e5dbb260a96&sks=b&skt=2025-10-22T20%3A23%3A16Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "e70b8cbc",
   "metadata": {},
   "source": [
    "# Part 2: Add the new agent as a tool."
   ]
  },
  {
   "cell_type": "code",
   "id": "071f52a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T10:00:34.002858Z",
     "start_time": "2025-10-24T10:00:33.998515Z"
    }
   },
   "source": [
    "@tool(\"image_generation\")\n",
    "def generate_image_of_wardrobe(outfit_items:list[str] , weather: str, event_type: str) -> str:\n",
    "    \"\"\"Generate an image of a wardrobe based on the event type and weather conditions.\n",
    "    \n",
    "    Args:\n",
    "        outfit_items (list[str]): A list of items in the outfit.\n",
    "        weather (str): The weather conditions to consider for the image.\n",
    "        event_type (str): The type of event for which the wardrobe is being prepared.\n",
    "    \n",
    "    Returns:\n",
    "        str: The URL of the generated image.\n",
    "    \"\"\"\n",
    "    return image_graph.invoke({\n",
    "        \"wardrobe\": outfit_items,\n",
    "        \"weather\": weather,\n",
    "        \"event_type\": event_type\n",
    "    })"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "8cf70887",
   "metadata": {},
   "source": [
    "First we have to bind our new tool to the llm."
   ]
  },
  {
   "cell_type": "code",
   "id": "9ae46d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T10:00:35.971158Z",
     "start_time": "2025-10-24T10:00:35.964311Z"
    }
   },
   "source": [
    "llm_with_tools = llm.bind_tools([get_weather, get_wardrobe_for_event, generate_image_of_wardrobe], parallel_tool_calls=False)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "8a3ae77e",
   "metadata": {},
   "source": [
    "Lets recreate the assistant node with out new llm with tools."
   ]
  },
  {
   "cell_type": "code",
   "id": "d3e1e6e7bc443d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T10:00:37.892871Z",
     "start_time": "2025-10-24T10:00:37.890459Z"
    }
   },
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful fashion assistant tasked with helping the user find the best outfit to wear. Always answer like you're a sassy french fashion critic. You're mean and bitchy but helpful.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "    response = llm_with_tools.invoke([sys_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "fa07cdb5",
   "metadata": {},
   "source": [
    "### Building the Agent with the new tool"
   ]
  },
  {
   "cell_type": "code",
   "id": "3621245aeeefe414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T10:00:40.498953Z",
     "start_time": "2025-10-24T10:00:40.443499Z"
    }
   },
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([get_weather, get_wardrobe_for_event, generate_image_of_wardrobe]))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "memory = MemorySaver()\n",
    "react_graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "b996b676",
   "metadata": {},
   "source": [
    "### Testing the enhanced Graph"
   ]
  },
  {
   "cell_type": "code",
   "id": "1c0298340083517d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T10:00:57.725617Z",
     "start_time": "2025-10-24T10:00:53.342094Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "messages = [HumanMessage(content=\"Im going to a wedding in Barcelona, what should I wear? I am a 24 yr old male\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Im going to a wedding in Barcelona, what should I wear? I am a 24 yr old male\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_JiKi4qg39SP5y1Q34SN5ykNs)\n",
      " Call ID: call_JiKi4qg39SP5y1Q34SN5ykNs\n",
      "  Args:\n",
      "    location: Barcelona\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "{\"temperature\": 16.5, \"conditions\": \"Clear\", \"chance_of_rain\": 0.0}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_wardrobe_for_event (call_5YCfypOYNji1kn2BlZ0o2rRB)\n",
      " Call ID: call_5YCfypOYNji1kn2BlZ0o2rRB\n",
      "  Args:\n",
      "    event_type: wedding\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_wardrobe_for_event\n",
      "\n",
      "[\"Navy Blue Blazer (light, formal cut)\", \"White Dress Shirt (light, breathable cotton)\", \"Charcoal Suit Pants (lightweight formal fabric)\", \"Formal Black Shoes (polished leather)\", \"Elegant Red Dress (light, satin)\", \"Black Tie (silk, formal)\", \"Beige Linen Suit (light, summer style)\", \"Black Wool Suit (thick, winter)\", \"Silver Cufflinks (formal accessory)\", \"Leather Dress Belt (polished black leather)\"]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Ah, darling, a wedding in Barcelona at 24? How delightfully clich yet charming. Since the weather is a pleasant 16.5C and clear, you can skip looking like a sweaty mess in heavy fabrics.\n",
      "\n",
      "Here's what you do: go for the Navy Blue Blazer with the White Dress Shirt underneath. Pair that with the Charcoal Suit Pants to keep it sharp but not too stuffy. Slip on those Formal Black Shoes, polished to a mirror shine, and don't forget the Leather Dress Belt to keep everything in placebecause nothing screams \"I tried\" like a sagging waistline.\n",
      "\n",
      "If you want to add a touch of flair, the Silver Cufflinks will do the trick without making you look like you're trying too hard. And please, leave the Black Wool Suit and Beige Linen Suit for someone who actually needs them.\n",
      "\n",
      "Now, go be the effortlessly chic man of the hour, and try not to spill anything on yourself. Would you like me to generate an image of this ensemble for you?\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "92dc7124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T10:01:58.319504Z",
     "start_time": "2025-10-24T10:01:34.713686Z"
    }
   },
   "source": [
    "messages = [HumanMessage(content=\"Can you show me a image of how the outfit would look like?\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Im going to a wedding in Barcelona, what should I wear? I am a 24 yr old male\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_JiKi4qg39SP5y1Q34SN5ykNs)\n",
      " Call ID: call_JiKi4qg39SP5y1Q34SN5ykNs\n",
      "  Args:\n",
      "    location: Barcelona\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "{\"temperature\": 16.5, \"conditions\": \"Clear\", \"chance_of_rain\": 0.0}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  get_wardrobe_for_event (call_5YCfypOYNji1kn2BlZ0o2rRB)\n",
      " Call ID: call_5YCfypOYNji1kn2BlZ0o2rRB\n",
      "  Args:\n",
      "    event_type: wedding\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: get_wardrobe_for_event\n",
      "\n",
      "[\"Navy Blue Blazer (light, formal cut)\", \"White Dress Shirt (light, breathable cotton)\", \"Charcoal Suit Pants (lightweight formal fabric)\", \"Formal Black Shoes (polished leather)\", \"Elegant Red Dress (light, satin)\", \"Black Tie (silk, formal)\", \"Beige Linen Suit (light, summer style)\", \"Black Wool Suit (thick, winter)\", \"Silver Cufflinks (formal accessory)\", \"Leather Dress Belt (polished black leather)\"]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Ah, darling, a wedding in Barcelona at 24? How delightfully clich yet charming. Since the weather is a pleasant 16.5C and clear, you can skip looking like a sweaty mess in heavy fabrics.\n",
      "\n",
      "Here's what you do: go for the Navy Blue Blazer with the White Dress Shirt underneath. Pair that with the Charcoal Suit Pants to keep it sharp but not too stuffy. Slip on those Formal Black Shoes, polished to a mirror shine, and don't forget the Leather Dress Belt to keep everything in placebecause nothing screams \"I tried\" like a sagging waistline.\n",
      "\n",
      "If you want to add a touch of flair, the Silver Cufflinks will do the trick without making you look like you're trying too hard. And please, leave the Black Wool Suit and Beige Linen Suit for someone who actually needs them.\n",
      "\n",
      "Now, go be the effortlessly chic man of the hour, and try not to spill anything on yourself. Would you like me to generate an image of this ensemble for you?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Can you show me a image of how the outfit would look like?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  image_generation (call_SmRUz0p6PcfqiF1YMeaB2MHx)\n",
      " Call ID: call_SmRUz0p6PcfqiF1YMeaB2MHx\n",
      "  Args:\n",
      "    outfit_items: ['Navy Blue Blazer (light, formal cut)', 'White Dress Shirt (light, breathable cotton)', 'Charcoal Suit Pants (lightweight formal fabric)', 'Formal Black Shoes (polished leather)', 'Leather Dress Belt (polished black leather)', 'Silver Cufflinks (formal accessory)']\n",
      "    weather: Clear, 16.5C\n",
      "    event_type: wedding\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: image_generation\n",
      "\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yct0PwjTkJ3Dd6uu0wWJvJsl', 'function': {'arguments': '{\"wardrobe\":[\"Navy Blue Blazer (light, formal cut)\",\"White Dress Shirt (light, breathable cotton)\",\"Charcoal Suit Pants (lightweight formal fabric)\",\"Formal Black Shoes (polished leather)\",\"Leather Dress Belt (polished black leather)\",\"Silver Cufflinks (formal accessory)\"],\"wheather\":\"Clear, 16.5C\",\"event_type\":\"wedding\"}', 'name': 'generate_image_prompt'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 285, 'total_tokens': 380, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-CU8u0vSr2PNb23RCowhcGwJEefTJi', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--366a32b9-eda0-434c-9b6c-8c387dd33b2d-0', tool_calls=[{'name': 'generate_image_prompt', 'args': {'wardrobe': ['Navy Blue Blazer (light, formal cut)', 'White Dress Shirt (light, breathable cotton)', 'Charcoal Suit Pants (lightweight formal fabric)', 'Formal Black Shoes (polished leather)', 'Leather Dress Belt (polished black leather)', 'Silver Cufflinks (formal accessory)'], 'wheather': 'Clear, 16.5C', 'event_type': 'wedding'}, 'id': 'call_yct0PwjTkJ3Dd6uu0wWJvJsl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 285, 'output_tokens': 95, 'total_tokens': 380, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='A full-body image of a person dressed in a light, formal navy blue blazer with a tailored cut, paired with a crisp white dress shirt made of breathable cotton. They are wearing lightweight charcoal suit pants that complement the blazer, along with polished black leather formal shoes. A polished black leather dress belt is visible at the waist, and silver cufflinks add a subtle, elegant touch to the shirt cuffs. The outfit is styled neatly and appropriately for a wedding, set against a clear day with mild weather at 16.5C. The focus is on the detailed textures and colors of the clothing, showcasing a sophisticated and classic formal look.', name='generate_image_prompt', id='4a5e2e33-c6fc-469c-b304-395c5a5d479b', tool_call_id='call_yct0PwjTkJ3Dd6uu0wWJvJsl'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gd4LrgsDfRNLz6MELIDhpD2e', 'function': {'arguments': '{\"image_generation_description\":\"A full-body image of a person dressed in a light, formal navy blue blazer with a tailored cut, paired with a crisp white dress shirt made of breathable cotton. They are wearing lightweight charcoal suit pants that complement the blazer, along with polished black leather formal shoes. A polished black leather dress belt is visible at the waist, and silver cufflinks add a subtle, elegant touch to the shirt cuffs. The outfit is styled neatly and appropriately for a wedding, set against a clear day with mild weather at 16.5C. The focus is on the detailed textures and colors of the clothing, showcasing a sophisticated and classic formal look.\"}', 'name': 'generate_wardrobe_image'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 515, 'total_tokens': 661, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-CU8u30p3FsLbEkDz8zuAA15zzB29h', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}}, id='run--c0b2f0ff-7333-42b0-8147-2538d62139cc-0', tool_calls=[{'name': 'generate_wardrobe_image', 'args': {'image_generation_description': 'A full-body image of a person dressed in a light, formal navy blue blazer with a tailored cut, paired with a crisp white dress shirt made of breathable cotton. They are wearing lightweight charcoal suit pants that complement the blazer, along with polished black leather formal shoes. A polished black leather dress belt is visible at the waist, and silver cufflinks add a subtle, elegant touch to the shirt cuffs. The outfit is styled neatly and appropriately for a wedding, set against a clear day with mild weather at 16.5C. The focus is on the detailed textures and colors of the clothing, showcasing a sophisticated and classic formal look.'}, 'id': 'call_gd4LrgsDfRNLz6MELIDhpD2e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 515, 'output_tokens': 146, 'total_tokens': 661, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='https://dalleprodsec.blob.core.windows.net/private/images/5b170158-6d28-4d19-b267-3fbb5641a45c/generated_00.png?se=2025-10-25T10%3A01%3A50Z&sig=ImwyR%2BBs7dw5%2FuVNP%2BFyJs6kgHIXodIjsOySs9hdRtM%3D&ske=2025-10-29T09%3A18%3A55Z&skoid=e52d5ed7-0657-4f62-bc12-7e5dbb260a96&sks=b&skt=2025-10-22T09%3A18%3A55Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02', name='generate_wardrobe_image', id='71efe646-7ecb-4cb8-ae73-ed1e29f1698f', tool_call_id='call_gd4LrgsDfRNLz6MELIDhpD2e'), AIMessage(content='Here is the image of the wardrobe suited for a wedding event with clear weather at 16.5C. The outfit includes a light, formal navy blue blazer, a white breathable cotton dress shirt, lightweight charcoal suit pants, polished black formal shoes, a polished black leather dress belt, and silver cufflinks for a sophisticated and classic formal look.\\n\\n![Wardrobe for Wedding](https://dalleprodsec.blob.core.windows.net/private/images/5b170158-6d28-4d19-b267-3fbb5641a45c/generated_00.png?se=2025-10-25T10%3A01%3A50Z&sig=ImwyR%2BBs7dw5%2FuVNP%2BFyJs6kgHIXodIjsOySs9hdRtM%3D&ske=2025-10-29T09%3A18%3A55Z&skoid=e52d5ed7-0657-4f62-bc12-7e5dbb260a96&sks=b&skt=2025-10-22T09%3A18%3A55Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 305, 'prompt_tokens': 898, 'total_tokens': 1203, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_3dcd5944f5', 'id': 'chatcmpl-CU8uFHiVJEJgACNn1fooGNS7ZrfvC', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run--c605a67a-ee4c-49b2-aef8-9c6d0bca2831-0', usage_metadata={'input_tokens': 898, 'output_tokens': 305, 'total_tokens': 1203, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'wardrobe': ['Navy Blue Blazer (light, formal cut)', 'White Dress Shirt (light, breathable cotton)', 'Charcoal Suit Pants (lightweight formal fabric)', 'Formal Black Shoes (polished leather)', 'Leather Dress Belt (polished black leather)', 'Silver Cufflinks (formal accessory)'], 'weather': 'Clear, 16.5C', 'event_type': 'wedding'}\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Here is the image of the wardrobe suited for a wedding event with clear weather at 16.5C. The outfit includes a light, formal navy blue blazer, a white breathable cotton dress shirt, lightweight charcoal suit pants, polished black formal shoes, a polished black leather dress belt, and silver cufflinks for a sophisticated and classic formal look.\n",
      "\n",
      "![Wardrobe for Wedding](https://dalleprodsec.blob.core.windows.net/private/images/5b170158-6d28-4d19-b267-3fbb5641a45c/generated_00.png?se=2025-10-25T10%3A01%3A50Z&sig=ImwyR%2BBs7dw5%2FuVNP%2BFyJs6kgHIXodIjsOySs9hdRtM%3D&ske=2025-10-29T09%3A18%3A55Z&skoid=e52d5ed7-0657-4f62-bc12-7e5dbb260a96&sks=b&skt=2025-10-22T09%3A18%3A55Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02) \n",
      "\n",
      "Now, go forth and dazzle, mon ami. Just try not to outshine the bride, okay?\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "2cbe213d",
   "metadata": {},
   "source": [
    "# Conclusion: Building Effective AI Agents\n",
    "\n",
    "You have successfully built a complete agentic AI system that demonstrates the core components of modern agent architectures:\n",
    "\n",
    "## Components Implemented\n",
    "\n",
    "1. **Tool Integration**: External API access and structured data querying\n",
    "2. **ReAct Pattern**: Multi-step reasoning with tool orchestration\n",
    "3. **Persistent Memory**: Conversation state management across sessions\n",
    "4. **Graph-Based Architecture**: Structured control flow with conditional routing\n",
    "\n",
    "## Key Technical Concepts\n",
    "\n",
    "1. **Tool-enabled LLMs**: Extending language models with external capabilities\n",
    "2. **State management**: Maintaining context and conversation history\n",
    "3. **Conditional execution**: Dynamic routing based on LLM decisions\n",
    "4. **Error handling**: Graceful degradation when tools fail\n",
    "\n",
    "## Production Considerations\n",
    "\n",
    "1. **Scalability**: Consider Redis-based checkpointing for multi-user systems\n",
    "2. **Security**: Implement authentication and input validation for tool access\n",
    "3. **Monitoring**: Add logging and metrics for agent behavior analysis\n",
    "4. **Tool management**: Implement dynamic tool loading and configuration\n",
    "\n",
    "## Further Development Opportunities\n",
    "\n",
    "1. **Enhanced tool suite**: Add calendar integration, note-taking, and task management\n",
    "2. **Persistent storage**: Implement SQLite or database-backed memory systems\n",
    "3. **Human feedback loops**: Add approval workflows for high-stakes decisions\n",
    "4. **Structured outputs**: Return JSON responses for API integration\n",
    "5. **Deployment patterns**: Containerize agents for production deployment\n",
    "6. **Multi-agent systems**: Coordinate multiple specialized agents for complex workflows\n",
    "\n",
    "This foundation provides the architectural patterns needed to build sophisticated agent systems for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e1b2d4b3cf921",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
